<!doctype html><html lang=en>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=robots content="noodp">
<meta http-equiv=x-ua-compatible content="IE=edge, chrome=1">
<title>Machine Learning Week2 Assignment - Torres' Tech Blog</title><meta name=Description content="记录我的学习之路"><meta property="og:title" content="Machine Learning Week2 Assignment">
<meta property="og:description" content="This article is for the solution of week 2 assignment of Machine Learning by Andrew Ng.
Assignment Introduction In this exercise, you need to implement one variable linear regression. The course has provided several files you would like to use and some of them you need to modify to implement the algorithm. Following list is the files they provide:
 ex1.m - Octave/MATLAB script that steps you through the exercise ex1 multi.">
<meta property="og:type" content="article">
<meta property="og:url" content="http://403unauthorized.github.io/2021/10/machine-learning-week2/"><meta property="og:image" content="http://403unauthorized.github.io/logo.ico"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2021-10-30T11:25:00+09:00">
<meta property="article:modified_time" content="2021-10-30T18:15:30+09:00"><meta property="og:site_name" content="Torres' Tech Blog">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="http://403unauthorized.github.io/logo.ico">
<meta name=twitter:title content="Machine Learning Week2 Assignment">
<meta name=twitter:description content="This article is for the solution of week 2 assignment of Machine Learning by Andrew Ng.
Assignment Introduction In this exercise, you need to implement one variable linear regression. The course has provided several files you would like to use and some of them you need to modify to implement the algorithm. Following list is the files they provide:
 ex1.m - Octave/MATLAB script that steps you through the exercise ex1 multi.">
<meta name=application-name content="Torres' Blog">
<meta name=apple-mobile-web-app-title content="Torres' Blog"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico>
<link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png>
<link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=http://403unauthorized.github.io/2021/10/machine-learning-week2/><link rel=prev href=http://403unauthorized.github.io/2021/10/aws-s3-and-iam-summary/><link rel=stylesheet href=/lib/normalize/normalize.min.055364f5be272caa092b0e6654c165828707f8ab971e2656383a6d6392bc345e.css integrity="sha256-BVNk9b4nLKoJKw5mVMFlgocH+KuXHiZWODptY5K8NF4="><link rel=stylesheet href=/css/style.min.1e2694bed152fa2922dbe909a441838ed693d88b1330f97485bfa8ed78da42df.css integrity="sha256-HiaUvtFS+iki2+kJpEGDjtaT2IsTMPl0hb+o7XjaQt8="><link rel=stylesheet href=/lib/fontawesome-free/all.min.876d023d9d10c97941b80c3b03e2a5b94631ff7a4af9cee5604a6a2d39718d84.css integrity="sha256-h20CPZ0QyXlBuAw7A+KluUYx/3pK+c7lYEpqLTlxjYQ="><link rel=stylesheet href=/lib/animate/animate.min.3c770e90f98eb21b0c042fafb49755af93306fbaf42e449524f94fae9fc83295.css integrity="sha256-PHcOkPmOshsMBC+vtJdVr5Mwb7r0LkSVJPlPrp/IMpU="><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Machine Learning Week2 Assignment","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"http:\/\/403unauthorized.github.io\/2021\/10\/machine-learning-week2\/"},"genre":"posts","keywords":"Linear Regression, Machine Learning","wordcount":975,"url":"http:\/\/403unauthorized.github.io\/2021\/10\/machine-learning-week2\/","datePublished":"2021-10-30T11:25:00+09:00","dateModified":"2021-10-30T18:15:30+09:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"Torres"},"description":""}</script></head>
<body header-desktop=fixed header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem('theme')?localStorage.getItem('theme')==='dark':'auto'==='auto'?window.matchMedia('(prefers-color-scheme: dark)').matches:'auto'==='dark')&&document.body.setAttribute('theme','dark')</script>
<div id=mask></div><div class=wrapper><header class=desktop id=header-desktop>
<div class=header-wrapper>
<div class=header-title>
<a href=/ title="Torres' Tech Blog"><span class=header-title-pre><i class="fa fa-theater-masks"></i></span><span id=id-1 class=typeit></span></a>
</div>
<div class=menu>
<div class=menu-inner><a class=menu-item href=/posts/> Posts </a><a class=menu-item href=/tags/> Tags </a><a class=menu-item href=/categories/> Categories </a><a class=menu-item href=/about/> About </a><span class="menu-item delimiter"></span><a href=javascript:void(0); class="menu-item language" title="Select Language">English<i class="fas fa-chevron-right fa-fw"></i>
<select class=language-select id=language-select-desktop onchange="location=this.value"><option value=/2021/10/machine-learning-week2/ selected>English</option></select>
</a><span class="menu-item search" id=search-desktop>
<input type=text placeholder="Search titles or contents..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search>
<i class="fas fa-search fa-fw"></i>
</a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear>
<i class="fas fa-times-circle fa-fw"></i>
</a>
<span class="search-button search-loading" id=search-loading-desktop>
<i class="fas fa-spinner fa-fw fa-spin"></i>
</span>
</span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i>
</a>
</div>
</div>
</div>
</header><header class=mobile id=header-mobile>
<div class=header-container>
<div class=header-wrapper>
<div class=header-title>
<a href=/ title="Torres' Tech Blog"><span class=header-title-pre><i class="fa fa-theater-masks"></i></span><span id=id-2 class=typeit></span></a>
</div>
<div class=menu-toggle id=menu-toggle-mobile>
<span></span><span></span><span></span>
</div>
</div>
<div class=menu id=menu-mobile><div class=search-wrapper>
<div class="search mobile" id=search-mobile>
<input type=text placeholder="Search titles or contents..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search>
<i class="fas fa-search fa-fw"></i>
</a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear>
<i class="fas fa-times-circle fa-fw"></i>
</a>
<span class="search-button search-loading" id=search-loading-mobile>
<i class="fas fa-spinner fa-fw fa-spin"></i>
</span>
</div>
<a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>
Cancel
</a>
</div><a class=menu-item href=/posts/ title>Posts</a><a class=menu-item href=/tags/ title>Tags</a><a class=menu-item href=/categories/ title>Categories</a><a class=menu-item href=/about/ title>About</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i>
</a><a href=javascript:void(0); class=menu-item title="Select Language">English<i class="fas fa-chevron-right fa-fw"></i>
<select class=language-select onchange="location=this.value"><option value=/2021/10/machine-learning-week2/ selected>English</option></select>
</a></div>
</div>
</header>
<div class="search-dropdown desktop">
<div id=search-dropdown-desktop></div>
</div>
<div class="search-dropdown mobile">
<div id=search-dropdown-mobile></div>
</div>
<main class=main>
<div class=container><div class=toc id=toc-auto>
<h2 class=toc-title>Contents</h2>
<div class=toc-content id=toc-content-auto></div>
</div><article class="page single"><h1 class="single-title animated flipInX">Machine Learning Week2 Assignment</h1><div class=post-meta>
<div class=post-meta-line><span class=post-author><a href=/ title=Author rel=" author" class=author><i class="fas fa-user-circle fa-fw"></i>Torres</a></span>&nbsp;<span class=post-category>included in <a href=/categories/machine-learning/><i class="far fa-folder fa-fw"></i>Machine Learning</a></span></div>
<div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2021-10-30>2021-10-30</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;975 words&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;5 minutes&nbsp;</div>
</div><div class="details toc" id=toc-static kept>
<div class="details-summary toc-title">
<span>Contents</span>
<span><i class="details-icon fas fa-angle-right"></i></span>
</div>
<div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents>
<ul>
<li>
<ul>
<li><a href=#assignment-introduction>Assignment Introduction</a></li>
<li><a href=#linear-regression-with-one-variable>Linear Regression with One Variable</a>
<ul>
<li><a href=#warm-up-exercise>Warm Up Exercise</a></li>
<li><a href=#plot-data>Plot Data</a></li>
<li><a href=#compute-cost-function>Compute Cost Function</a></li>
<li><a href=#gradient-descent>Gradient Descent</a></li>
</ul>
</li>
<li><a href=#linear-regression-with-multiple-variables-optional>Linear Regression with Multiple Variables (Optional)</a></li>
</ul>
</li>
</ul>
</nav></div>
</div><div class=content id=content><p>This article is for the solution of week 2 assignment of <a href=https://www.coursera.org/learn/machine-learning/home/welcome target=_blank rel="noopener noreffer">Machine Learning</a> by Andrew Ng.</p>
<h2 id=assignment-introduction>Assignment Introduction</h2>
<p>In this exercise, you need to implement one variable linear regression. The course has provided several files you would like to use and some of them you need to modify to implement the algorithm. Following list is the files they provide:</p>
<ul>
<li>ex1.m - Octave/MATLAB script that steps you through the exercise ex1</li>
<li>multi.m - Octave/MATLAB script for the later parts of the exercise</li>
<li>ex1data1.txt - Dataset for linear regression with one variable</li>
<li>ex1data2.txt - Dataset for linear regression with multiple variables</li>
<li>submit.m - Submission script that sends your solutions to our servers</li>
<li>[(*) warmUpExercise.m - Simple example function in Octave/MATLAB](#Warm Up Exercise)</li>
<li>[(*) plotData.m - Function to display the dataset](#Plot Data)</li>
<li>[(*) computeCost.m - Function to compute the cost of linear regression](#Compute\ Cost\ Function)</li>
<li>[(*) gradientDescent.m - Function to run gradient descent](#Gradient Descent)</li>
<li>(†) computeCostMulti.m - Cost function for multiple variables</li>
<li>(†) gradientDescentMulti.m - Gradient descent for multiple variables</li>
<li>(†) featureNormalize.m - Function to normalize features</li>
<li>(†) normalEqn.m - Function to compute the normal equations</li>
</ul>
<blockquote>
<p>* indicates files you will need to complete
† indicates optional exercises</p>
</blockquote>
<h2 id=linear-regression-with-one-variable>Linear Regression with One Variable</h2>
<h3 id=warm-up-exercise>Warm Up Exercise</h3>
<p>In <code>warmUpExercise.m</code> file, you need to write a program to output an 5x5 identity matrix.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-matlab data-lang=matlab><span class=k>function</span><span class=w> </span>A <span class=p>=</span><span class=w> </span><span class=nf>warmUpExercise</span><span class=p>()</span><span class=w>
</span><span class=w></span><span class=c>%WARMUPEXERCISE Example function in octave</span>
<span class=c>%   A = WARMUPEXERCISE() is an example function that returns the 5x5 identity matrix</span>

<span class=n>A</span> <span class=p>=</span> <span class=p>[];</span>
<span class=c>% ============= YOUR CODE HERE ==============</span>
<span class=c>% Instructions: Return the 5x5 identity matrix </span>
<span class=c>%               In octave, we return values by defining which variables</span>
<span class=c>%               represent the return values (at the top of the file)</span>
<span class=c>%               and then set them accordingly. </span>

<span class=n>A</span> <span class=p>=</span> <span class=nb>eye</span><span class=p>(</span><span class=mi>5</span><span class=p>);</span>
<span class=c>% ===========================================</span>
<span class=k>end</span>

</code></pre></td></tr></table>
</div>
</div><h3 id=plot-data>Plot Data</h3>
<p>In <code>plotData.m</code> file, you need to plot the data using X and y passed as parameters.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-matlab data-lang=matlab><span class=k>function</span><span class=w> </span><span class=nf>plotData</span><span class=p>(</span>x, y<span class=p>)</span><span class=w>
</span><span class=w></span><span class=c>%PLOTDATA Plots the data points x and y into a new figure </span>
<span class=c>%   PLOTDATA(x,y) plots the data points and gives the figure axes labels of</span>
<span class=c>%   population and profit.</span>

<span class=n>figure</span><span class=p>;</span> <span class=c>% open a new figure window</span>

<span class=c>% ====================== YOUR CODE HERE ======================</span>
<span class=c>% Instructions: Plot the training data into a figure using the </span>
<span class=c>%               &#34;figure&#34; and &#34;plot&#34; commands. Set the axes labels using</span>
<span class=c>%               the &#34;xlabel&#34; and &#34;ylabel&#34; commands. Assume the </span>
<span class=c>%               population and revenue data have been passed in</span>
<span class=c>%               as the x and y arguments of this function.</span>
<span class=c>%</span>
<span class=c>% Hint: You can use the &#39;rx&#39; option with plot to have the markers</span>
<span class=c>%       appear as red crosses. Furthermore, you can make the</span>
<span class=c>%       markers larger by using plot(..., &#39;rx&#39;, &#39;MarkerSize&#39;, 10);</span>

<span class=n>plot</span><span class=p>(</span><span class=n>x</span><span class=p>,</span><span class=n>y</span><span class=p>,</span><span class=s>&#39;rx&#39;</span><span class=p>,</span><span class=s>&#39;MarkerSize&#39;</span><span class=p>,</span><span class=mi>8</span><span class=p>)</span>
<span class=c>% ============================================================</span>
<span class=k>end</span>

</code></pre></td></tr></table>
</div>
</div><h3 id=compute-cost-function>Compute Cost Function</h3>
<p>Cost function is one of the important parts in week 2. Following is the formula of cost function:
$$
J(\theta_0, \theta_1,&mldr;,\theta_n) = \frac{1}{2m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)}) - y^{(i)})^2
$$
Because we had $h_{\theta}(x) = \theta_0 + \theta_1x$, it equals to $h_{\theta}(x) = \theta_0x_0 + \theta_1x_1$ where $x_0 = 1$. So we can simplify the linear model:
$$
\begin{align}
h_{\theta}(x) &= \theta_0 + \theta_1x \<br>
&= h_{\theta}(x) = \theta_0x_0 + \theta_1x_1 \space # x_0=1 \<br>
&= \theta^{T}x
\end{align}
$$
Then we can define uppercase X as &ldquo;designed matrix&rdquo;, which contains all training examples:
$$
X = \left[
\begin{matrix}
x_0^{1} & x_1^{1} &&mldr;& x_n^{1} \<br>
x_0^{2} & x_1^{2} &&mldr;& x_n^{2} \<br>
x_0^{3} & x_1^{3} &&mldr;& x_n^{3} \<br>
&mldr;&&mldr;&&mldr;&&mldr;\<br>
x_0^{m} & x_1^{m} &&mldr;& x_n^{m} \<br>
\end{matrix}
\right],\space
y = \left[
\begin{matrix}
y^1\<br>
y^2\<br>
y^3\<br>
&mldr;\<br>
y^m
\end{matrix}
\right]
$$
So above cost function can be simplified as follows:
$$
J(\theta) = \frac{1}{2m}(\theta^{T}X - y)^2
$$
Finally we have the correct code:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-matlab data-lang=matlab><span class=k>function</span><span class=w> </span>J <span class=p>=</span><span class=w> </span><span class=nf>computeCost</span><span class=p>(</span>X, y, theta<span class=p>)</span><span class=w>
</span><span class=w></span><span class=c>%COMPUTECOST Compute cost for linear regression</span>
<span class=c>%   J = COMPUTECOST(X, y, theta) computes the cost of using theta as the</span>
<span class=c>%   parameter for linear regression to fit the data points in X and y</span>

<span class=c>% Initialize some useful values</span>
<span class=n>m</span> <span class=p>=</span> <span class=nb>length</span><span class=p>(</span><span class=n>y</span><span class=p>);</span> <span class=c>% number of training examples</span>

<span class=c>% You need to return the following variables correctly </span>
<span class=n>J</span> <span class=p>=</span> <span class=mi>0</span><span class=p>;</span>

<span class=c>% ====================== YOUR CODE HERE ======================</span>
<span class=c>% Instructions: Compute the cost of a particular choice of theta</span>
<span class=c>%               You should set J to the cost.</span>
<span class=n>J</span> <span class=p>=</span> <span class=p>(</span><span class=mi>1</span> <span class=o>/</span> <span class=p>(</span><span class=mi>2</span> <span class=o>*</span> <span class=n>m</span><span class=p>))</span> <span class=o>*</span> <span class=n>sum</span><span class=p>((</span><span class=n>X</span> <span class=o>*</span> <span class=n>theta</span> <span class=o>-</span> <span class=n>y</span><span class=p>)</span> <span class=o>.^</span> <span class=mi>2</span><span class=p>);</span>

<span class=c>% =========================================================================</span>

<span class=k>end</span>
</code></pre></td></tr></table>
</div>
</div><h3 id=gradient-descent>Gradient Descent</h3>
<p>Andrew Ng has clarified very clearly in the video lectures, so let&rsquo;s see the final answer:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-matlab data-lang=matlab><span class=k>function</span><span class=w> </span>[theta, J_history] <span class=p>=</span><span class=w> </span><span class=nf>gradientDescent</span><span class=p>(</span>X, y, theta, alpha, num_iters<span class=p>)</span><span class=w>
</span><span class=w></span><span class=c>%GRADIENTDESCENT Performs gradient descent to learn theta</span>
<span class=c>%   theta = GRADIENTDESCENT(X, y, theta, alpha, num_iters) updates theta by </span>
<span class=c>%   taking num_iters gradient steps with learning rate alpha</span>

<span class=c>% Initialize some useful values</span>
<span class=n>m</span> <span class=p>=</span> <span class=nb>length</span><span class=p>(</span><span class=n>y</span><span class=p>);</span> <span class=c>% number of training examples</span>
<span class=n>J_history</span> <span class=p>=</span> <span class=nb>zeros</span><span class=p>(</span><span class=n>num_iters</span><span class=p>,</span> <span class=mi>1</span><span class=p>);</span>

<span class=k>for</span> <span class=n>iter</span> <span class=p>=</span> <span class=mi>1</span><span class=p>:</span><span class=n>num_iters</span>

    <span class=c>% ====================== YOUR CODE HERE ======================</span>
    <span class=c>% Instructions: Perform a single gradient step on the parameter vector</span>
    <span class=c>%               theta. </span>
    <span class=c>%</span>
    <span class=c>% Hint: While debugging, it can be useful to print out the values</span>
    <span class=c>%       of the cost function (computeCost) and gradient here.</span>
    <span class=c>%</span>
    
    <span class=n>temp</span> <span class=p>=</span> <span class=nb>zeros</span><span class=p>(</span><span class=nb>length</span><span class=p>(</span><span class=n>theta</span><span class=p>),</span> <span class=mi>1</span><span class=p>);</span>
    <span class=k>for</span> <span class=n>it</span> <span class=p>=</span> <span class=mi>1</span><span class=p>:</span><span class=nb>length</span><span class=p>(</span><span class=n>temp</span><span class=p>)</span>
        <span class=n>temp</span><span class=p>(</span><span class=n>it</span><span class=p>)</span> <span class=p>=</span> <span class=n>theta</span><span class=p>(</span><span class=n>it</span><span class=p>)</span> <span class=o>-</span> <span class=p>(</span><span class=n>alpha</span> <span class=o>/</span> <span class=n>m</span><span class=p>)</span> <span class=o>*</span> <span class=n>sum</span><span class=p>((</span><span class=n>X</span> <span class=o>*</span> <span class=n>theta</span> <span class=o>-</span> <span class=n>y</span><span class=p>)</span> <span class=o>.*</span> <span class=n>X</span><span class=p>(:,</span><span class=n>it</span><span class=p>));</span>
    <span class=k>end</span>
    <span class=n>theta</span> <span class=p>=</span> <span class=n>temp</span><span class=p>;</span>

    <span class=c>% ============================================================</span>

    <span class=c>% Save the cost J in every iteration    </span>
    <span class=n>J_history</span><span class=p>(</span><span class=n>iter</span><span class=p>)</span> <span class=p>=</span> <span class=n>computeCost</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>theta</span><span class=p>);</span>

<span class=k>end</span>

<span class=k>end</span>

</code></pre></td></tr></table>
</div>
</div><p>As Andrew mentioned in video lecture we need to <strong>simultaneously</strong> update $\theta_j$, so we created one temp vector to save $\theta_0$ and $\theta_1$.</p>
<h2 id=linear-regression-with-multiple-variables-optional>Linear Regression with Multiple Variables (Optional)</h2>
</div><div class=post-footer id=post-footer>
<div class=post-info>
<div class=post-info-line>
<div class=post-info-mod>
<span>Updated on 2021-10-30&nbsp;<a class=git-hash href=https://github.com/403Unauthorized/hugo/commit/68b0a0da0505ab3d1472363a28610e907e13956c target=_blank title="commit by Torres Lei(torres.lei96@gmail.com) 68b0a0da0505ab3d1472363a28610e907e13956c: updates">
<i class="fas fa-hashtag fa-fw"></i>68b0a0d</a></span>
</div>
<div class=post-info-license></div>
</div>
<div class=post-info-line>
<div class=post-info-md></div>
<div class=post-info-share>
<span><a href=javascript:void(0); title="Share on Linkedin" data-sharer=linkedin data-url=http://403unauthorized.github.io/2021/10/machine-learning-week2/><i class="fab fa-linkedin fa-fw"></i></a><a href=javascript:void(0); title="Share on WhatsApp" data-sharer=whatsapp data-url=http://403unauthorized.github.io/2021/10/machine-learning-week2/ data-title="Machine Learning Week2 Assignment" data-web><i class="fab fa-whatsapp fa-fw"></i></a><a href=javascript:void(0); title="Share on Reddit" data-sharer=reddit data-url=http://403unauthorized.github.io/2021/10/machine-learning-week2/><i class="fab fa-reddit fa-fw"></i></a><a href=javascript:void(0); title="Share on Line" data-sharer=line data-url=http://403unauthorized.github.io/2021/10/machine-learning-week2/ data-title="Machine Learning Week2 Assignment"><i data-svg-src=/lib/simple-icons/icons/line.min.svg></i></a><a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=http://403unauthorized.github.io/2021/10/machine-learning-week2/ data-title="Machine Learning Week2 Assignment"><i class="fab fa-weibo fa-fw"></i></a><a href=javascript:void(0); title="Share on 人人" data-sharer=renren data-url=http://403unauthorized.github.io/2021/10/machine-learning-week2/><i class="fab fa-renren fa-fw"></i></a><a href=javascript:void(0); title="Share on 百度" data-sharer=baidu data-url=http://403unauthorized.github.io/2021/10/machine-learning-week2/ data-title="Machine Learning Week2 Assignment"><i data-svg-src=/lib/simple-icons/icons/baidu.min.svg></i></a><a href=javascript:void(0); title="Share on Evernote" data-sharer=evernote data-url=http://403unauthorized.github.io/2021/10/machine-learning-week2/ data-title="Machine Learning Week2 Assignment"><i class="fab fa-evernote fa-fw"></i></a><a href=javascript:void(0); title="Share on Skype" data-sharer=skype data-url=http://403unauthorized.github.io/2021/10/machine-learning-week2/ data-title="Machine Learning Week2 Assignment"><i class="fab fa-skype fa-fw"></i></a></span>
</div>
</div>
</div>
<div class=post-info-more>
<section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/linear-regression/>Linear Regression</a>,&nbsp;<a href=/tags/machine-learning/>Machine Learning</a></section>
<section>
<span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span>
</section>
</div>
<div class=post-nav><a href=/2021/10/aws-s3-and-iam-summary/ class=prev rel=prev title="Aws S3 and Iam Summary"><i class="fas fa-angle-left fa-fw"></i>Aws S3 and Iam Summary</a></div>
</div>
<div id=comments><div id=disqus_thread class=comment></div><noscript>
Please enable JavaScript to view the comments powered by <a href=https://disqus.com/?ref_noscript>Disqus</a>.
</noscript></div></article></div>
</main><footer class=footer>
<div class=footer-container><div class=footer-line>Powered by <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.88.1">Hugo</a> | Theme - <a href=https://github.com/dillonzq/LoveIt target=_blank rel="noopener noreffer" title="LoveIt 0.2.10"><i class="far fa-kiss-wink-heart fa-fw"></i> LoveIt</a>
</div><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2021</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank>Torres</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div>
</div>
</footer></div>
<div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top">
<i class="fas fa-arrow-up fa-fw"></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments">
<i class="fas fa-comment fa-fw"></i>
</a>
</div><link rel=stylesheet href=/lib/katex/katex.min.4710034e669c7ff17f823f9ba12cf8a36582d65b007f79cbc4a3c11d7db2e4ca.css integrity="sha256-RxADTmacf/F/gj+boSz4o2WC1lsAf3nLxKPBHX2y5Mo="><link rel=stylesheet href=/lib/katex/copy-tex.min.bf9ff4137fec38f6255419e142d0883c9c52090885d746f80eee12b273d9b3e0.css integrity="sha256-v5/0E3/sOPYlVBnhQtCIPJxSCQiF10b4Du4SsnPZs+A="><script type=text/javascript src=https://torres-blog.disqus.com/embed.js defer></script><script type=text/javascript src=/lib/smooth-scroll/smooth-scroll.min.bcff85fb5e00d68802850b393ac7792c997f722f536f38e26638c46dca8e5eb6.js integrity="sha256-vP+F+14A1ogChQs5Osd5LJl/ci9TbzjiZjjEbcqOXrY="></script><script type=text/javascript src=/lib/autocomplete/autocomplete.min.615590a2ca2b667afa7c02ef396f5500b62e22795ddbb46448f90494605d09a5.js integrity="sha256-YVWQosorZnr6fALvOW9VALYuInld27RkSPkElGBdCaU="></script><script type=text/javascript src=/lib/lunr/lunr.min.df84a2d58ea594c04a3371b48d020b55ea10284c2ec636e4e331965d7313e29b.js integrity="sha256-34Si1Y6llMBKM3G0jQILVeoQKEwuxjbk4zGWXXMT4ps="></script><script type=text/javascript src=/lib/lazysizes/lazysizes.min.fb649fcae62177dfe63e67081ddceb830b5ce1f05a4184e9bbb7d87ac4b8f4e5.js integrity="sha256-+2SfyuYhd9/mPmcIHdzrgwtc4fBaQYTpu7fYesS49OU="></script><script type=text/javascript src=/lib/clipboard/clipboard.min.8a7739925f4c03586479852df840b7061948832a7fda30c8c812d2ea4dd4c4f2.js integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI="></script><script type=text/javascript src=/lib/sharer/sharer.min.9c88f86c7f0820287113f6236200459832693656e80d7556cc80a93dfbd45813.js integrity="sha256-nIj4bH8IIChxE/YjYgBFmDJpNlboDXVWzICpPfvUWBM="></script><script type=text/javascript src=/lib/typeit/typeit.min.491c13689db70b6adb3176a9a792644be7578a2f931521f5cb199d313a21c359.js integrity="sha256-SRwTaJ23C2rbMXapp5JkS+dXii+TFSH1yxmdMTohw1k="></script><script type=text/javascript src=/lib/katex/katex.min.17f5dd6b9f123dd7140abfb18521b3f4c036cd004f6f40121182a8865f140877.js integrity="sha256-F/Xda58SPdcUCr+xhSGz9MA2zQBPb0ASEYKohl8UCHc="></script><script type=text/javascript src=/lib/katex/auto-render.min.f74776a677f0d2be0af0264058f928e2ba455d0b19bc985304660d922a43a6b2.js integrity="sha256-90d2pnfw0r4K8CZAWPko4rpFXQsZvJhTBGYNkipDprI="></script><script type=text/javascript src=/lib/katex/copy-tex.min.2ab2237329021bc443986c8327f6e61357fb68a54e5d233d224023718c02207d.js integrity="sha256-KrIjcykCG8RDmGyDJ/bmE1f7aKVOXSM9IkAjcYwCIH0="></script><script type=text/javascript src=/lib/katex/mhchem.min.5cea356d6025c5a2f18c454c83ec5674dbb04fab1cd1d75569e77788c6b6f888.js integrity="sha256-XOo1bWAlxaLxjEVMg+xWdNuwT6sc0ddVaed3iMa2+Ig="></script><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:10},comment:{},data:{"id-1":"Torres","id-2":"Torres"},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{highlightTag:"em",lunrIndexURL:"/index.json",maxResultLength:10,noResultsFound:"No results found",snippetLength:50,type:"lunr"},typeit:{cursorChar:"|",cursorSpeed:1e3,data:{"id-1":["id-1"],"id-2":["id-2"]},duration:-1,speed:100}}</script><script type=text/javascript src=/js/theme.min.f51938f3065a40ee841bcb558e4330e31fd26c0ea55343fff8770b88b0319a3c.js integrity="sha256-9Rk48wZaQO6EG8tVjkMw4x/SbA6lU0P/+HcLiLAxmjw="></script></body>
</html>