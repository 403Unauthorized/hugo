[{"categories":null,"content":" 我是一个软件开发工程师，目前在乐天工作，主要面向乐天市场。 ","date":"2021-10-03","objectID":"/zh-cn/about/:0:0","tags":null,"title":"关于我","uri":"/zh-cn/about/"},{"categories":null,"content":"技能 编程语言: Java 8, 11; Golang 框架: Spring Framework, Spring Boot 2.x, Spring Cloud, Reactor(Spring WebFlux) 容器: Kubernetes, Docker ","date":"2021-10-03","objectID":"/zh-cn/about/:1:0","tags":null,"title":"关于我","uri":"/zh-cn/about/"},{"categories":null,"content":"工作经验 Rakuten Group, Inc. 2021-04-01 ~ 现在 软件工程师 - ECMPD …TODO 株式会社 C\u0026J 2019-12-26 ~ 2021-02-28 软件工程师 …TODO ","date":"2021-10-03","objectID":"/zh-cn/about/:2:0","tags":null,"title":"关于我","uri":"/zh-cn/about/"},{"categories":["Programming","Cloud Native"],"content":"Ribbon 是 Netflix 公司开源的一个负载均衡项目。可以在 Zuul 中使用 Ribbon 做负载均衡，也可以和 Feign 结合使用。在 Spring Cloud 开发中使用的最多的可能就是 RestTemplate 和 Ribbon。代码可能如下： @Configuration public class RibbonConfig { @Bean @LoadBalanced public RestTemplate restTemplate() { return new RestTemplate(); } } 使用 RestTemplate 消费服务接口的代码可能是这样的： @Service public class RibbonService { @Autowired private RestTemplate restTemplate; public String hi(String name) { return restTemplate.getForObject(\"http://eureka-client/hi?name=\"+name,String.class); } } RestTemplate 在 Spring 中就已经存在了，查看以上的代码可以发现 RestTemplate Bean 上有一个 @LoadBalanced 注解，这个注解标记在 RestTemplate 上，让负载均衡客户端 LoadBalancerClient 来配置它。 ","date":"2021-10-03","objectID":"/zh-cn/2021/10/spring-cloud-ribbon/:0:0","tags":["Spring Cloud","Java"],"title":"Spring Cloud Ribbon","uri":"/zh-cn/2021/10/spring-cloud-ribbon/"},{"categories":["Programming","Cloud Native"],"content":"负载均衡初始化 spring-cloud-commons 包中定义了 LoadBalancerClient 接口，它是 Ribbon 中一个非常重要的组件。继承结构如下： ","date":"2021-10-03","objectID":"/zh-cn/2021/10/spring-cloud-ribbon/:1:0","tags":["Spring Cloud","Java"],"title":"Spring Cloud Ribbon","uri":"/zh-cn/2021/10/spring-cloud-ribbon/"},{"categories":["Programming","Cloud Native"],"content":"LoadBalancerAutoConfiguration 而在 spring-cloud-commons 中相同的包下面，可以看到 LoadBalancerAutoConfiguration，看类名就能看出来这是一个自动配置类，会在启动时自动加载其中的配置： LoadBalancerAutoConfiguration @Configuration @ConditionalOnClass(RestTemplate.class) @ConditionalOnBean(LoadBalancerClient.class) @EnableConfigurationProperties(LoadBalancerRetryProperties.class) public class LoadBalancerAutoConfiguration { // 省略代码。。。主要是对 LoadBalancerInterceptor 和 RetryLoadBalancerInterCeptor 的等进行配置，这里我们看类上的注解@ConditionalOnBean和@ConditionalOnClass } 可以看到该自动配置类上有注解 @ConditionalOnBean(LoadBalancerClient.class) 和 @ConditionalOnClass(RestTemplate.class)，也就是说此类的生效条件是： 1、当前工程中要有 RestTemplate 类 2、在 Spring 的 IOC 容器中必须要有 LoadBalancerClient 的实现 Bean 然后我们看到 org.springframework.cloud.netflix.ribbon 这个包，其中有一个 RibbonAutoConfiguration.java 类（继承于 LoadBalancerClient）。查看到其中配置的 Bean，我们可以发现，只要引入了这个包，就一定会创建一个 RibbonLoadBalancerClient 实例对象加入到 IOC 容器中，并且触发 LoadBalancerAutoConfiguration 配置。 @Configuration @Conditional(RibbonAutoConfiguration.RibbonClassesConditions.class) @RibbonClients @AutoConfigureAfter( name = \"org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration\") @AutoConfigureBefore({ LoadBalancerAutoConfiguration.class, AsyncLoadBalancerAutoConfiguration.class }) @EnableConfigurationProperties({ RibbonEagerLoadProperties.class, ServerIntrospectorProperties.class }) public class RibbonAutoConfiguration { // 省略。。。 @Bean @ConditionalOnMissingBean(LoadBalancerClient.class) public LoadBalancerClient loadBalancerClient() { return new RibbonLoadBalancerClient(springClientFactory()); } // 省略。。。 } 我们再看回 LoadBalancerAutoConfiguration，该自动化配置类，主要做了几个配置： 1、维护了一个被 @LoadBalanced 注解修饰的 RestTemplate 对象列表 @Configuration @ConditionalOnClass(RestTemplate.class) @ConditionalOnBean(LoadBalancerClient.class) @EnableConfigurationProperties(LoadBalancerRetryProperties.class) public class LoadBalancerAutoConfiguration { @LoadBalanced @Autowired(required = false) private List\u003cRestTemplate\u003e restTemplates = Collections.emptyList(); // ... } 2、为每个对象通过调用 RestTemplateCustomizer 添加了一个 LoadBalancerInterceptor 和 RetryLoadBalancerInterceptor 拦截器。他们都是 ClientHttpRequestInterceptor 接口的实现类，ClientHttpRequestInterceptor 是 RestTemplate 的请求拦截器。 @Bean public SmartInitializingSingleton loadBalancedRestTemplateInitializerDeprecated( final ObjectProvider\u003cList\u003cRestTemplateCustomizer\u003e\u003e restTemplateCustomizers) { return () -\u003e restTemplateCustomizers.ifAvailable(customizers -\u003e { for (RestTemplate restTemplate : LoadBalancerAutoConfiguration.this.restTemplates) { for (RestTemplateCustomizer customizer : customizers) { customizer.customize(restTemplate); } } }); } ","date":"2021-10-03","objectID":"/zh-cn/2021/10/spring-cloud-ribbon/:1:1","tags":["Spring Cloud","Java"],"title":"Spring Cloud Ribbon","uri":"/zh-cn/2021/10/spring-cloud-ribbon/"},{"categories":["Programming","Cloud Native"],"content":"拦截器配置 LoadBalancerInterceptor 拦截器 // LoadBalancerAutoconfiguration.java @Configuration @ConditionalOnMissingClass(\"org.springframework.retry.support.RetryTemplate\") static class LoadBalancerInterceptorConfig { @Bean public LoadBalancerInterceptor ribbonInterceptor( LoadBalancerClient loadBalancerClient, LoadBalancerRequestFactory requestFactory) { return new LoadBalancerInterceptor(loadBalancerClient, requestFactory); } @Bean @ConditionalOnMissingBean public RestTemplateCustomizer restTemplateCustomizer( final LoadBalancerInterceptor loadBalancerInterceptor) { return restTemplate -\u003e { // 此处可见 LoadBalancerInterceptor 是 ClientHttpRequestInterceptor 的实现类 List\u003cClientHttpRequestInterceptor\u003e list = new ArrayList\u003c\u003e( restTemplate.getInterceptors()); list.add(loadBalancerInterceptor); restTemplate.setInterceptors(list); }; } } RetryLoadBalancerInterceptor 拦截器 @Configuration @ConditionalOnClass(RetryTemplate.class) public static class RetryInterceptorAutoConfiguration { @Bean @ConditionalOnMissingBean public RetryLoadBalancerInterceptor ribbonInterceptor( LoadBalancerClient loadBalancerClient, LoadBalancerRetryProperties properties, LoadBalancerRequestFactory requestFactory, LoadBalancedRetryFactory loadBalancedRetryFactory) { return new RetryLoadBalancerInterceptor(loadBalancerClient, properties, requestFactory, loadBalancedRetryFactory); } @Bean @ConditionalOnMissingBean public RestTemplateCustomizer restTemplateCustomizer( final RetryLoadBalancerInterceptor loadBalancerInterceptor) { return restTemplate -\u003e { // RetryLoadBalancerInterceptor 也是 ClientHttpRequestInterceptor 的实现类 List\u003cClientHttpRequestInterceptor\u003e list = new ArrayList\u003c\u003e( restTemplate.getInterceptors()); list.add(loadBalancerInterceptor); restTemplate.setInterceptors(list); }; } } 由此可见，在程序启动的时候，如果环境中引入了相应的依赖，则会在初始化时对负载均衡器进行配置，实现的方式则是为被 @LoadBalanced 注解修饰的 RestTemplate 对象添加负载均衡拦截器。 ","date":"2021-10-03","objectID":"/zh-cn/2021/10/spring-cloud-ribbon/:1:2","tags":["Spring Cloud","Java"],"title":"Spring Cloud Ribbon","uri":"/zh-cn/2021/10/spring-cloud-ribbon/"},{"categories":["Programming","Cloud Native"],"content":"LoadBalancerClient 源码分析 首先我们先跟进到上文提到的拦截器(LoadBalancerInterceptor)中，可以发现，在拦截方法（intercept）中，最终是调用了 LoadBalancerClient 的 execute 方法。 public class LoadBalancerInterceptor implements ClientHttpRequestInterceptor { private LoadBalancerClient loadBalancer; // ... @Override public ClientHttpResponse intercept(final HttpRequest request, final byte[] body, final ClientHttpRequestExecution execution) throws IOException { final URI originalUri = request.getURI(); String serviceName = originalUri.getHost(); Assert.state(serviceName != null, \"Request URI does not contain a valid hostname: \" + originalUri); return this.loadBalancer.execute(serviceName, this.requestFactory.createRequest(request, body, execution)); } } LoadBalancerClient 接口中有三个方法： public interface LoadBalancerClient extends ServiceInstanceChooser { \u003cT\u003e T execute(String serviceId, LoadBalancerRequest\u003cT\u003e request) throws IOException; // 使用 LoadBalancer 的 ServiceInstance，对其执行请求，返回结果 \u003cT\u003e T execute(String serviceId, ServiceInstance serviceInstance, LoadBalancerRequest\u003cT\u003e request) throws IOException; // 构造一个包含主机和端口的真正的 url // http://serviceId/path/... --\u003e http://host:port/path/... URI reconstructURI(ServiceInstance instance, URI original); } 其父类 ServiceInstanceChooser 中的方法： public interface ServiceInstanceChooser { ServiceInstance choose(String serviceId); // 通过 serviceId 选择服务 } 从继承关系里，LoadBalancerClient 的实现类就是 RibbonLoadBalancerClient 类了。 // RibbonLoadBalancerClient.java public \u003cT\u003e T execute(String serviceId, LoadBalancerRequest\u003cT\u003e request, Object hint) throws IOException { // 通过服务名获取到负载均衡器，ILoadBalancer 实现类为 DynamicServerListLoadBalancer，下文会提到 ILoadBalancer loadBalancer = getLoadBalancer(serviceId); // 通过调用负载均衡器的 chooseServer 方法获取到服务器 Server server = getServer(loadBalancer, hint); if (server == null) { throw new IllegalStateException(\"No instances available for \" + serviceId); } RibbonServer ribbonServer = new RibbonServer(serviceId, server, isSecure(server, serviceId), serverIntrospector(serviceId).getMetadata(server)); return execute(serviceId, ribbonServer, request); } @Override public \u003cT\u003e T execute(String serviceId, ServiceInstance serviceInstance, LoadBalancerRequest\u003cT\u003e request) throws IOException { Server server = null; if (serviceInstance instanceof RibbonServer) { server = ((RibbonServer) serviceInstance).getServer(); } if (server == null) { throw new IllegalStateException(\"No instances available for \" + serviceId); } RibbonLoadBalancerContext context = this.clientFactory .getLoadBalancerContext(serviceId); RibbonStatsRecorder statsRecorder = new RibbonStatsRecorder(context, server); try { T returnVal = request.apply(serviceInstance); statsRecorder.recordStats(returnVal); return returnVal; } // catch IOException and rethrow so RestTemplate behaves correctly catch (IOException ex) { statsRecorder.recordStats(ex); throw ex; } catch (Exception ex) { statsRecorder.recordStats(ex); ReflectionUtils.rethrowRuntimeException(ex); } return null; } RibbonLoadBalancerClient 在 execute 中调用 getServer 方法来获取 Server 对象，跟踪源码可以看到，最终是通过 ILoadBalancer 的 chooseServer 去选择服务实例。 // RibbonLoadBalancerClient.java protected Server getServer(String serviceId) { // 通过 SpringClientFactory 获取 LoadBalancer 对象 // 内部是通过反射，用构造方法构造一个实例对象 return getServer(getLoadBalancer(serviceId), null); } protected Server getServer(ILoadBalancer loadBalancer) { return getServer(loadBalancer, null); } protected Server getServer(ILoadBalancer loadBalancer, Object hint) { if (loadBalancer == null) { return null; } // Use 'default' on a null hint, or just pass it on? // 通过 ILoadBalancer 的 chooseServer 方法获取 Server 对象 return loadBalancer.chooseServer(hint != null ? hint : \"default\"); } public interface ILoadBalancer { // 添加一个 Server 集合 public void addServers(List\u003cServer\u003e newServers); // 根据 key 获取 Server public Server chooseServer(Object key); // 标记某个服务下线 public void markServerDown(Server server); // 获取可用的 Server 集合 public List\u003cServer\u003e getReachableServers(); // 获取所有的 Server集合 public List\u003cServer\u003e getAllServers(); } ","date":"2021-10-03","objectID":"/zh-cn/2021/10/spring-cloud-ribbon/:2:0","tags":["Spring Cloud","Java"],"title":"Spring Cloud Ribbon","uri":"/zh-cn/2021/10/spring-cloud-ribbon/"},{"categories":["Programming","Cloud Native"],"content":"DynamicServerListLoadBalancer 跟踪源码后，我们可以找到 ILoadBalancer 的继承结构如下，DynamicServerListLoadBalancer 继承了 ILoadBalancer，也就是说我们可以通过跟踪这个类来搞清楚 Ribbon 是如何实现负载均衡的。 ","date":"2021-10-03","objectID":"/zh-cn/2021/10/spring-cloud-ribbon/:3:0","tags":["Spring Cloud","Java"],"title":"Spring Cloud Ribbon","uri":"/zh-cn/2021/10/spring-cloud-ribbon/"},{"categories":["Programming","Cloud Native"],"content":"成员介绍 查看 DynamicServerListLoadBalancer，BaseLoadBalancer，ILoadBalancer 这三个类，配置了 IClientConfig，IRule，IPing，ServerList，ServerListFilter 和 ILoadBalancer，在 BaseLoadBalancer 中，默认进行了以下配置： IClientConfig ribbonClientConfig：DefaultClientConfigImpl 配置（用于客户端的负载均衡配置） IRule ribbonRule：默认路由策略为 RoundRobinRule IPing ribbonPing：DummyPing ServerList ribbonServerList：ConfigurationBasedServerList ServerListFilter ribbonServerListFilter：ZonePreferenceServerListFilter ILoadBalancer ribbonLoadBalancer：ZoneAwareLoadBalancer ","date":"2021-10-03","objectID":"/zh-cn/2021/10/spring-cloud-ribbon/:3:1","tags":["Spring Cloud","Java"],"title":"Spring Cloud Ribbon","uri":"/zh-cn/2021/10/spring-cloud-ribbon/"},{"categories":["Programming","Cloud Native"],"content":"IRule IRule 有很多默认的实现类，都通过不同的算法来处理负载均衡，Ribbon 中实现的 IRule 又以下几种： IRule 实现类 BestAvailableRule：选择最小请求数 ClientConfigEnabledRoundRobinRule：轮询 RandomRule：随机选择 Server RoundRobinRule：轮询 WeightedResponseTimeRule：根据响应时间分配一个权重 weight，weight越低，被选择的可能性就越低 ZoneAvoidanceRule：根据 Server 的 Zone 区域和可用性轮询选择 ","date":"2021-10-03","objectID":"/zh-cn/2021/10/spring-cloud-ribbon/:3:2","tags":["Spring Cloud","Java"],"title":"Spring Cloud Ribbon","uri":"/zh-cn/2021/10/spring-cloud-ribbon/"},{"categories":["Programming","Cloud Native"],"content":"IPing IPing 的实现类又 PingUrl，PingConstant，NoOpPing，DummyPing 和 NIWSDiscoveryPing。IPing 接口中有一个 isAlive 方法。 public boolean isAlive(Server Server); 通过向 Server 发送 ping 信号，来判断 Server 是否可用 IPing 实现类 PingUrl 真实的去ping 某个url，判断其是否alive PingConstant 固定返回某服务是否可用，默认返回true，即可用 NoOpPing 不去ping,直接返回true,即可用。 DummyPing 直接返回true，并实现了initWithNiwsConfig方法。 NIWSDiscoveryPing，根据DiscoveryEnabledServer的InstanceInfo的InstanceStatus去判断，如果为InstanceStatus.UP，则为可用，否则不可用。 ","date":"2021-10-03","objectID":"/zh-cn/2021/10/spring-cloud-ribbon/:3:3","tags":["Spring Cloud","Java"],"title":"Spring Cloud Ribbon","uri":"/zh-cn/2021/10/spring-cloud-ribbon/"},{"categories":["Programming","Cloud Native"],"content":"ServerList ServerList 是定义了获取所有的 Server 的注册列表信息的接口。 public interface ServerList\u003cT extends Server\u003e { public List\u003cT\u003e getInitialListOfServers(); public List\u003cT\u003e getUpdatedListOfServers(); } 其实现类是 DiscoveryEnabledNIWSServerList。 ","date":"2021-10-03","objectID":"/zh-cn/2021/10/spring-cloud-ribbon/:3:4","tags":["Spring Cloud","Java"],"title":"Spring Cloud Ribbon","uri":"/zh-cn/2021/10/spring-cloud-ribbon/"},{"categories":["Programming","Cloud Native"],"content":"ServerListFilter ServerListFilter 可根据配置过滤或者根据特性动态获取符合条件的 Server 列表。该类也是一个接口 public interface ServerListFilter\u003cT extends Server\u003e { public List\u003cT\u003e getFilteredListOfServers(List\u003cT\u003e servers); } ","date":"2021-10-03","objectID":"/zh-cn/2021/10/spring-cloud-ribbon/:3:5","tags":["Spring Cloud","Java"],"title":"Spring Cloud Ribbon","uri":"/zh-cn/2021/10/spring-cloud-ribbon/"},{"categories":["Programming","Cloud Native"],"content":"源码分析 在 SpringClientFactory 中获取 LoadBalancer 的方法中，我们能看到获取实例的方法是通过反射获取到实现类的含有 IClientConfig 参数的构造方法来构造实例对象。 // SpringClientFactory.java static \u003cC\u003e C instantiateWithConfig(AnnotationConfigApplicationContext context, Class\u003cC\u003e clazz, IClientConfig config) { C result = null; try { // 获取到 ILoadBalancer 实现类的构造方法 Constructor\u003cC\u003e constructor = clazz.getConstructor(IClientConfig.class); // 通过构造方法构造实例对象 result = constructor.newInstance(config); } catch (Throwable e) { // Ignored } // ... return result; } ","date":"2021-10-03","objectID":"/zh-cn/2021/10/spring-cloud-ribbon/:4:0","tags":["Spring Cloud","Java"],"title":"Spring Cloud Ribbon","uri":"/zh-cn/2021/10/spring-cloud-ribbon/"},{"categories":["Programming","Cloud Native"],"content":"DynamicServerListLoadBalancer 构造方法 DynamicServerListLoadBalancer 中的构造方法中调用了一个方法 - initWithNiwsConfig()。 // DynamicServerListLoadBalancer.java public DynamicServerListLoadBalancer(IClientConfig clientConfig) { initWithNiwsConfig(clientConfig); } public initWithNiwsConfig(IClientConfig clientConfig) { try { super.initWithNiwsConfig(clientConfig); // 获取 ServerList 的 classname String niwsServerListClassname = clientConfig.getPropertyAsString(CommonClientConfigKey.NIWSServerListClassName, DefaultClientConfigImpl.DEFAULT_SERVER_LIST_CLASS); // 构造 ServerList ServerList\u003cT\u003e niwsServerListImpl = (ServerList\u003cT\u003e) ClientFactory.instantiateInstanceWithClientConfig(niwsServerListClassName, clientConfig); // 如果该 ServerList 是 AbstractServerList 的子类，则获取并设置过滤器 if (niwsServerListImpl instanceof AbstractServerList) { AbstractServerListFilter\u003cT\u003e niwsFilter = ((AbstractServerList) niwsServerListImpl).getFilterImpl(clientConfig); niwsFilter.setLoadBalancerStats(getLoadBalancerStats()); this.filter = niwsFilter; } // 获取 ServerListUpdater 的 classname String serverListUpdaterClassName = clientConfig.getPropertyAsString( CommonClientConfigKey.ServerListUpdaterClassname, DefaultClientConfigImpl.DEFAULT_SERVER_LIST_UPDATER_CLASS ); // 通过 classname 构造 ServerListUpdater 设置到 serverListUpdater 成员属性中 this.serverListUpdater = (ServerListUpdater) ClientFactory .instantiateInstanceWithClientConfig(serverListUpdaterClassName, clientConfig); // 执行剩下的初始化操作 restOfInit(clientConfig); } } ","date":"2021-10-03","objectID":"/zh-cn/2021/10/spring-cloud-ribbon/:4:1","tags":["Spring Cloud","Java"],"title":"Spring Cloud Ribbon","uri":"/zh-cn/2021/10/spring-cloud-ribbon/"},{"categories":["Programming","Cloud Native"],"content":"restOfInit 执行剩下的初始化操作 // DynamicServerListLoadBalancer.java void restOfInit(IClientConfig clientConfig) { boolean primeConnection = this.isEnablePrimingConnections(); // 将这个关闭来避免 BaseLoadBalancer.setServerList() 中重复的异步启动 this.setEnablePrimingConnections(false); enableAndInitLearnNewServersFeature(); updateListOfServers(); // 用来获取所有的 Server if (primeConnection \u0026\u0026 this.getPrimeConnections() != null) { this.getPrimeConnections().primeConnections(getReachableServers()); } this.setEnablePrimingConnections(primeConnection); LOGGER.info(\"DynamicServerListLoadBalancer for client {} initialized: {}\", clientConfig.getClientName(), this.toString()); } 上面源码中的 updateListOfServers() 最终是通过 serverListImpl.getUpdatedListOfServers() 来获取所有的服务列表的： // DynamicServerListLoadBalancer.java @VisibleForTesting public void updateListOfServers() { List\u003cT\u003e servers = new ArrayList\u003cT\u003e(); if (serverListImpl != null) { servers = serverListImpl.getUpdatedListOfServers(); LOGGER.debug(\"List of Servers for {} obtained from Discovery client: {}\", getIdentifier(), servers); if (filter != null) { // 如果配置了过滤器，则将符合条件的 server 筛选出来 servers = filter.getFilteredListOfServers(servers); LOGGER.debug(\"Filtered List of Servers for {} obtained from Discovery client: {}\", getIdentifier(), servers); } } updateAllServerList(servers); } 其中 serverListImpl 是 ServerList 的实现类 - DiscoveryEnabledNIWSServerList。而 getUpdatedListOfServers() 的具体实现为： // DiscoveryEnabledNIWSServerList.java @Override public List\u003cDiscoveryEnabledServer\u003e getInitialListOfServers() { return obtainServersViaDiscovery(); } public List\u003cDiscoveryEnabledServer\u003e getUpdatedListOfServers() { return obtainServersViaDiscovery(); } ","date":"2021-10-03","objectID":"/zh-cn/2021/10/spring-cloud-ribbon/:4:2","tags":["Spring Cloud","Java"],"title":"Spring Cloud Ribbon","uri":"/zh-cn/2021/10/spring-cloud-ribbon/"},{"categories":["Programming","Cloud Native"],"content":"obtainServersViaDiscovery // DiscoveryEnabledNIWSServerList.java private List\u003cDiscoveryEnabledServer\u003e obtainServersViaDiscovery() { List\u003cDiscoveryEnabledServer\u003e serverList = new ArrayList\u003cDiscoveryEnabledServer\u003e(); if (eurekaClientProvider == null || eurekaClientProvider.get() == null) { logger.warn(\"EurekaClient has not been initialized yet, returning an empty list\"); return new ArrayList\u003cDiscoveryEnabledServer\u003e(); } EurekaClient eurekaClient = eurekaClientProvider.get(); if (vipAddresses!=null){ for (String vipAddress : vipAddresses.split(\",\")) { // if targetRegion is null, it will be interpreted as the same region of client List\u003cInstanceInfo\u003e listOfInstanceInfo = eurekaClient.getInstancesByVipAddress(vipAddress, isSecure, targetRegion); for (InstanceInfo ii : listOfInstanceInfo) { if (ii.getStatus().equals(InstanceStatus.UP)) { if(shouldUseOverridePort){ if(logger.isDebugEnabled()){ logger.debug(\"Overriding port on client name: \" + clientName + \" to \" + overridePort); } // copy is necessary since the InstanceInfo builder just uses the original reference, // and we don't want to corrupt the global eureka copy of the object which may be // used by other clients in our system InstanceInfo copy = new InstanceInfo(ii); if(isSecure){ ii = new InstanceInfo.Builder(copy).setSecurePort(overridePort).build(); }else{ ii = new InstanceInfo.Builder(copy).setPort(overridePort).build(); } } DiscoveryEnabledServer des = new DiscoveryEnabledServer(ii, isSecure, shouldUseIpAddr); des.setZone(DiscoveryClient.getZone(ii)); serverList.add(des); } } if (serverList.size()\u003e0 \u0026\u0026 prioritizeVipAddressBasedServers){ break; // if the current vipAddress has servers, we dont use subsequent vipAddress based servers } } } return serverList; } 看到这里，可以知道负载均衡器 Ribbon 是通过 Eureka Client 来获取注册列表信息，然后通过配置的路由规则 IRule 来路由。但是它从 Eureka Client 获取注册信息的时间间隔是多久呢？ ","date":"2021-10-03","objectID":"/zh-cn/2021/10/spring-cloud-ribbon/:4:3","tags":["Spring Cloud","Java"],"title":"Spring Cloud Ribbon","uri":"/zh-cn/2021/10/spring-cloud-ribbon/"},{"categories":["Programming","Cloud Native"],"content":"定时任务更新服务器列表和状态 在构造 DynamicServerListLoadBalancer 的构造方法中的第一行是调用父类中的 initWithNiwsConfig 方法。 // DynamicServerListLoadBalancer.java public initWithNiwsConfig(IClientConfig clientConfig) { try { super.initWithNiwsConfig(clientConfig); } // ... } 于是我们跟踪到 BaseLoadBalancer 的 initWithNiwsConfig 方法中： // BaseLoadBalancer.java @Override public void initWithNiwsConfig(IClientConfig clientConfig) { try { initWithNiwsConfig(clientConfig, ClientFactory::instantiateInstanceWithClientConfig); } catch (Exception e) { throw new RuntimeException(\"Error initializing load balancer\", e); } } @Override public void initWithNiwsConfig(IClientConfig clientConfig, Factory factory) { S// ... try { // ... initWithConfig(clientConfig, rule, ping, stats); } catch (Exception e) { throw new RuntimeException(\"Error initializing load balancer\", e); } } void initWithConfig(IClientConfig clientConfig, IRule rule, IPing ping, LoadBalancerStats stats) { // ... setPingInterval(pingIntervalTime); setMaxTotalPingTime(maxTotalPingTime); // cross associate with each other // i.e. Rule,Ping meet your container LB // LB, these are your Ping and Rule guys ... setRule(rule); setPing(ping); // ... } 以上只保留了关键代码。调用到 initWithConfig 方法中，会执行 setPingInterval(pingIntervalTime) 方法。 public void setPingInterval(int pingIntervalSeconds) { if (pingIntervalSeconds \u003c 1) { return; } this.pingIntervalSeconds = pingIntervalSeconds; if (logger.isDebugEnabled()) { logger.debug(\"LoadBalancer [{}]: pingIntervalSeconds set to {}\", name, this.pingIntervalSeconds); } setupPingTask(); // since ping data changed } 其中开启了一个定时任务：setupPingTask() 。在该方法内部使用 ShutdownEnabledTimer 初始化了一个定时器，并且设置每10秒调用 PingTask 任务。 // BaseLoadBalancer.java // 定时任务 void setupPingTask() { if (canSkipPing()) { return; } if (lbTimer != null) { lbTimer.cancel(); } lbTimer = new ShutdownEnabledTimer(\"NFLoadBalancer-PingTimer-\" + name, true); lbTimer.schedule(new PingTask(), 0, pingIntervalSeconds * 1000); // 默认10秒执行一次 forceQuickPing(); } PingTask 是 BaseLoadBalancer 的内部类，根据 IPingStrategy 策略来发送 ping 请求获取和更新服务器列表，默认策略是 SerialPingStrategy。在 PingTask 的 run 方法中，执行了另一个内部类 Pinger 的 runPinger 方法。 // BaseLoadBalancer.java // 内部类 PingTask class PingTask extends TimerTask { public void run() { try { new Pinger(pingStrategy).runPinger(); } catch (Exception e) { logger.error(\"LoadBalancer [{}]: Error pinging\", name, e); } } } // 内部类 Pinger class Pinger { private final IPingStrategy pingerStrategy; public Pinger(IPingStrategy pingerStrategy) { this.pingerStrategy = pingerStrategy; } public void runPinger() throws Exception { // 用 CAS 设置 pingInProgress 为 true，代表正在执行 Ping 任务。 // 如果设置失败，则表示有线程正在执行 Ping 任务，这里就不再执行 if (!pingInProgress.compareAndSet(false, true)) { return; // Ping in progress - nothing to do } // we are \"in\" - we get to Ping Server[] allServers = null; boolean[] results = null; Lock allLock = null; Lock upLock = null; try { /* * The readLock should be free unless an addServer operation is * going on... */ // 读锁应该是空闲状态，除了 addServer 操作正在执行。 allLock = allServerLock.readLock(); // 加读锁，避免其他线程修改 serverList allLock.lock(); allServers = allServerList.toArray(new Server[allServerList.size()]); // 解锁 allLock.unlock(); int numCandidates = allServers.length; // 向每个服务器发送 ping 请求，得到一个布尔值的结果集（服务器是否存活 - 能否请求成功） results = pingerStrategy.pingServers(ping, allServers); final List\u003cServer\u003e newUpList = new ArrayList\u003cServer\u003e(); final List\u003cServer\u003e changedServers = new ArrayList\u003cServer\u003e(); // 遍历当前所有Server for (int i = 0; i \u003c numCandidates; i++) { // 获取第 i 个 Server 是当前否为存活状态（UP） boolean isAlive = results[i]; Server svr = allServers[i]; // 获取 ping 之前的服务器状态 boolean oldIsAlive = svr.isAlive(); // 将该服务器状态改为当前获取到的状态 svr.setAlive(isAlive); if (oldIsAlive != isAlive) { // 如果之前状态与当前获取的状态不一致 // 加入到状态更改过的服务器列表中 changedServers.add(svr); // 输出日志：当前服务器状态修改 logger.debug(\"LoadBalancer [{}]: Server [{}] status changed to {}\", name, svr.getId(), (isAlive ? \"ALIVE\" : \"DEAD\")); } if (isAlive) { // 如果获取到的当前状态为 true（存活UP状态） // 则将该服务器加入到 newUpList 中，用于后面更新至存活服务器列表 newUpList.add(svr); }","date":"2021-10-03","objectID":"/zh-cn/2021/10/spring-cloud-ribbon/:4:4","tags":["Spring Cloud","Java"],"title":"Spring Cloud Ribbon","uri":"/zh-cn/2021/10/spring-cloud-ribbon/"},{"categories":["Programming","Cloud Native"],"content":"总结 由此可见，Ribbon的负载均衡，主要是通过 LoadBalancerClient 来实现的，而 Load’BalancerClient 又将具体实现交给了 ILoadBalancer 来处理，ILoadBalancer 通过配置 IRule、IPing 等信息，向 Eureka 获取服务注册列表，并且在初始化时开启一个定时任务，10s 一次向 EurekaClient 发送 ping 请求，来判断服务的可用性，如果服务的可用性发生改变或者服务数量与之前的不一致，则更新当前服务器列表或重新拉取。最后 ILoadBalancer 获取到这些服务列表之后，便可以根据 IRule 来进行负载均衡。 而 RestTemplate 被 @LoadBalanced 注解后，能够实现负载均衡，主要是通过给 RestTemplate 添加拦截器，在请求前通过拦截器（负载均衡）获取到真正的请求地址，最后进行服务调用。 ","date":"2021-10-03","objectID":"/zh-cn/2021/10/spring-cloud-ribbon/:5:0","tags":["Spring Cloud","Java"],"title":"Spring Cloud Ribbon","uri":"/zh-cn/2021/10/spring-cloud-ribbon/"},{"categories":["Programming","Cloud Native"],"content":"Ref Ribbon 源码 Spring Cloud Commons 源码 Spring Cloud Netflix 源码 Spring Cloud Netflix Ribbon 官方文档 Spring Cloud Ribbon踩坑记录及原理解析 Ribbon原理分析 - Spring For All 来源: Java Stack 文章作者: Ryan 文章链接: https://403unauthorized.github.io/deep-in-ribbon/ 本文章著作权归作者所有，任何形式的转载都请注明出处。 ","date":"2021-10-03","objectID":"/zh-cn/2021/10/spring-cloud-ribbon/:6:0","tags":["Spring Cloud","Java"],"title":"Spring Cloud Ribbon","uri":"/zh-cn/2021/10/spring-cloud-ribbon/"},{"categories":["Programming"],"content":"我们在学习 Java 并发编程的时候，看到的最多的就是 synchronized 关键字了，它可以解决很多线程安全问题，随着深入学习，我们知道 synchronized 是一个重量级锁，效率相对于 Lock 来说并不是那么好。但是经过 Java 几个版本的优化之后，synchronized 并不显得那么笨重了。下面我们来看一下 synchronized 的实现机制，和 Java 对它进行了什么样的升级。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-synchronized/:0:0","tags":["Java","Concurrency"],"title":"Synchronized 关键字","uri":"/zh-cn/2021/10/java-synchronized/"},{"categories":["Programming"],"content":"实现原理 Synchronized 保证了方法或者代码块在运行时，同一时间只有一个线程可以执行，并保证了对共享变量的内存可见性。 Java 中 synchronized 集中实现方法： 非静态同步方法：锁住当前实例对象 public synchronized void test() { } 静态同步方法：锁住当前类的 class 对象 public static synchronized void test() { } 同步代码块：锁住括号中的对象 public void test() { synchronized (this) { } } 我们利用工具查看生成的 class 文件，生成的 class 文件如下： 从以上 class 文件我们可以看出，同步代码块是通过 monitorenter 和 monitorexit 来实现的，同步方法是依靠方法修饰符中的 ACC_SYNCHRONIZED 实现。 同步代码块：moniterenter 指令会插入到同步代码块开始的位置，moniterexit 插入到同步代码块结束的位置，JVM 需要保证每个 monitorenter 都有一个 monitorexit 相对应。任何对象都有一个 monitor 与之相关联，当 monitor 被持有后，它将处于锁定状态。线程执行到 moniterenter 指令时，将会尝试获取当前对象对应的 monitor 所有权（这个过程就是获取锁）。 同步方法：同步方法中没有 monitorenter 和 monitorexit，取而代之的是在 flags 中添加了 ACC_SYNCHRONIZED 标识，JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用（方法调用时，调用指令将会检查方法是否含有 ACC_SYNCHRONIZED 访问标志，如果有，调用线程将会先持有 monitor。如果同步方法执行期间抛出了异常，而且在方法内部无法处理异常，则这个方法所持有的 monitor 将会在异常抛到同步方法之外时自动释放）。使用调用该方法的对象或方法所属 Class 在 JVM 的内部对象表示 Klass 做为锁对象。 关于 monitorenter 和 moniterexit 这两条指令 在 JVM 的规范中有这样一句话： Each object is associated with a monitor. A monitor is locked if and only if it has an owner. The thread that executes monitorenter attempts to gain ownership of the monitor associated with objectref, as follows: • If the entry count of the monitor associated with objectref is zero, the thread enters the monitor and sets its entry count to one. The thread is then the owner of the monitor. • If the thread already owns the monitor associated with objectref, it reenters the monitor, incrementing its entry count. • If another thread already owns the monitor associated with objectref, the thread blocks until the monitor’s entry count is zero, then tries again to gain ownership. 以上引用也说明了，每个对象都关联了一个 monitor，如果一个monitor被占用则它处于锁定状态。线程在执行 monitorenter 指令时会尝试获取对象关联的 monitor 的所有权。 如果 monitor 的进入数为0，则该线程进入 monitor，并将进入数设置为1，该线程为该 monitor 的所有者。 如果一个线程已经占有了对象关联的 monitor，它会重新进入，并将进入数加1。 如果已经有另一个线程占有了该 monitor，则该线程会阻塞直到 monitor 的进入数为0，然后尝试获取所有权。 The thread that executes monitorexit must be the owner of the monitor associated with the instance referenced by objectref. The thread decrements the entry count of the monitor associated with objectref. If as a result the value of the entry count is zero, the thread exits the monitor and is no longer its owner. Other threads that are blocking to enter the monitor are allowed to attempt to do so. 大致意思是：执行 monitorexit 的线程必须是 objectref 所对应的 monitor 的所有者。该指令执行时，线程会将 monitor 的进入数减1。如果进入数减1之后为0，则该线程退出 monitor 并且不再是它的所有者。被阻塞的其他线程将允许尝试获取所有权。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-synchronized/:1:0","tags":["Java","Concurrency"],"title":"Synchronized 关键字","uri":"/zh-cn/2021/10/java-synchronized/"},{"categories":["Programming"],"content":"Java 对象头和 Monitor ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-synchronized/:2:0","tags":["Java","Concurrency"],"title":"Synchronized 关键字","uri":"/zh-cn/2021/10/java-synchronized/"},{"categories":["Programming"],"content":"Java 对象头 对象在堆内存中的布局分为三块区域：对象头、实例数据和对其填充。 实例变量：存放类和父类的属性信息，如果是数组，还包括数组的长度，这部分内存为4字节。 填充数据：JVM 要求对象的其实地址必须为8字节的整数倍，所以有可能数据需要填充（非必须）。 Java 的对象头是实现 synchronized 的锁对象的基础。一般情况，synchronized 使用的锁对象都存在 Java 对象头中。JVM 采用两个字节来存储对象头（如果对象是数组，则使用三个字节，多出来的字节存储数组长度），主要是由 Mark Word 和类型指针组成。 虚拟机位数 头对象结构 说明 32/64bit Mark Word 存储对象的 hashCode，锁信息、分代年龄、GC标志、偏向线程ID、偏向时间戳等信息 32/64bit Class Metadata Address 类型指针指向对象的类元数据，JVM 通过这个指针确定对象是哪个类的实例 由于对象头的信息是与对象自身定义的数据没有关系的额外存储成本，因此考虑到 JVM 的空间效率，Mark Word 被设计成一个非固定的数据结构，以存储更多有效的数据，它会根据对象状态的变化复用自己的存储空间。Mark Word 会根据程序的运行而发生变化（以下是32位虚拟机默认的存储结构和其他变化状态）。 32位 JVM 的 Mark Word 默认存储结构： 锁状态 25bit 4bit 1bit是否是偏向锁 2bit 锁标志位 无锁状态 对象HashCode 对象分代年龄 0 01 状态变化（32位虚拟机）： 其中轻量级锁和偏向锁时在 Java 6 对 synchronized 锁进行优化后新增的。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-synchronized/:2:1","tags":["Java","Concurrency"],"title":"Synchronized 关键字","uri":"/zh-cn/2021/10/java-synchronized/"},{"categories":["Programming"],"content":"Monitor Monitor 可以被理解为监视器，在 Hotspot 中，它是由 ObjectMonitor 实现的（位于 HotSpot 虚拟机源码的 ObjectMonitor.hpp文件中，C++实现），其主要数据结构为： ObjectMonitor() { _header = NULL; _count = 0; //记录个数 _waiters = 0, _recursions = 0; _object = NULL; _owner = NULL; _WaitSet = NULL; //处于wait状态的线程，会被加入到_WaitSet _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; FreeNext = NULL ; _EntryList = NULL ; //处于等待锁block状态的线程，会被加入到该列表 _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ; } ObjectMonitor 中有两个队列 —— _WaitSet, _EntryList（当多个线程同时访问一段同步代码时，首先会进入 _EntryList 集合，当线程拥有对象的 monitor 后，ObjectMonitor 会将 _owner 变量设置为当前线程，并将计数器 _count 加1，如果该线程调用了 wait() 方法，它将会释放当前持有的 monitor， _owner 将恢复为 NULL，同时该线程会进入 _WaitSet 等待被唤醒）。它们是用来保存 ObjectWaiter 对象列表（每个等待的线程都会被封装为 ObjectWaiter 对象），底层实现原理不再叙述(C++实现的，我也没看过)。我们可以用一张图来简单概述它的数据结构。 其中： Owner：初始化为 NULL，当线程成功拥有该锁时保存线程唯一标识，锁被释放后又置为 NULL。 EntryQ：关联一个系统互斥锁（semaphore），阻塞所有试图锁住monitor record失败的线程。 RcThis:表示blocked或waiting在该monitor record上的所有线程的个数。 Nest:用来实现重入锁的计数。 HashCode:保存从对象头拷贝过来的HashCode值（可能还包含GC age）。 Candidate:用来避免不必要的阻塞或等待线程唤醒，因为每一次只有一个线程能够成功拥有锁，如果每次前一个释放锁的线程唤醒所有正在阻塞或等待的线程，会引起不必要的上下文切换（从阻塞到就绪然后因为竞争锁失败又被阻塞）从而导致性能严重下降。Candidate只有两种可能的值0表示没有需要唤醒的线程1表示要唤醒一个继任线程来竞争锁。 摘自：【死磕Java并发】—–深入分析synchronized的实现原理 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-synchronized/:3:0","tags":["Java","Concurrency"],"title":"Synchronized 关键字","uri":"/zh-cn/2021/10/java-synchronized/"},{"categories":["Programming"],"content":"Java 中锁的优化 Jdk 1.6 对锁的实现做了大量的优化（轻量级锁，偏向锁，自旋锁，适应性自旋锁，锁消除，锁粗化），锁主要存在四种状态（依次）：无锁状态，偏向锁状态，轻量级锁状态，重量级锁状态。它们会随着锁竞争的激烈而升级，锁只能升级不能降级（为了提高获得锁和释放锁的效率）。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-synchronized/:4:0","tags":["Java","Concurrency"],"title":"Synchronized 关键字","uri":"/zh-cn/2021/10/java-synchronized/"},{"categories":["Programming"],"content":"自旋锁 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-synchronized/:4:1","tags":["Java","Concurrency"],"title":"Synchronized 关键字","uri":"/zh-cn/2021/10/java-synchronized/"},{"categories":["Programming"],"content":"适应性自旋锁 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-synchronized/:4:2","tags":["Java","Concurrency"],"title":"Synchronized 关键字","uri":"/zh-cn/2021/10/java-synchronized/"},{"categories":["Programming"],"content":"锁消除 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-synchronized/:4:3","tags":["Java","Concurrency"],"title":"Synchronized 关键字","uri":"/zh-cn/2021/10/java-synchronized/"},{"categories":["Programming"],"content":"锁粗化 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-synchronized/:4:4","tags":["Java","Concurrency"],"title":"Synchronized 关键字","uri":"/zh-cn/2021/10/java-synchronized/"},{"categories":["Programming"],"content":"偏向锁 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-synchronized/:4:5","tags":["Java","Concurrency"],"title":"Synchronized 关键字","uri":"/zh-cn/2021/10/java-synchronized/"},{"categories":["Programming"],"content":"轻量级锁 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-synchronized/:4:6","tags":["Java","Concurrency"],"title":"Synchronized 关键字","uri":"/zh-cn/2021/10/java-synchronized/"},{"categories":["Programming"],"content":"重量级锁 通过对象内部的监视器 monitor 实现，而 monitor 的本质是依赖于底层操作系统的 Mutex Lock 实现，操作系统实现线程之间的切换需要从用户态到内核态的切换，切换成本非常高。 参考文章： Biased Locking in HotSpot JVM内部细节之一：synchronized关键字及实现细节(轻量级锁Lightweight Locking) 【死磕Java并发】—–深入分析synchronized的实现原理 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-synchronized/:4:7","tags":["Java","Concurrency"],"title":"Synchronized 关键字","uri":"/zh-cn/2021/10/java-synchronized/"},{"categories":["Programming"],"content":"volatile 应该经常听说或者用到的。它在并发编程中起到了什么作用呢？ volatile 能禁止编译器和CPU对指令重排序 对 volatile 变量的操作插入内存屏障，保证内存的可见性 这是我学习 volatile 的笔记，在这里记录一下。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-volatile/:0:0","tags":["Java"],"title":"Volatile 学习总结","uri":"/zh-cn/2021/10/java-volatile/"},{"categories":["Programming"],"content":"volatile 在 JVM 中如何实现 被 volatile 修饰的变量在编译之后的指令中，定义变量的 flags 会加上 ACC_VOLATILE 标志。javap -v 查看字节码。 Classfile /Users/leiyongqi/IdeaProjects/study/target/classes/com/keanu/io/study/concurrency/VolatileDemo.class Last modified 2019-10-15; size 583 bytes MD5 checksum 0b39c03d7d60166f7ab82b07bc3fc58d Compiled from \"VolatileDemo.java\" public class com.keanu.io.study.concurrency.VolatileDemo minor version: 0 major version: 49 flags: ACC_PUBLIC, ACC_SUPER Constant pool: #1 = Methodref #6.#23 // java/lang/Object.\"\u003cinit\u003e\":()V #2 = Fieldref #3.#24 // com/keanu/io/study/concurrency/VolatileDemo.i:I #3 = Class #25 // com/keanu/io/study/concurrency/VolatileDemo #4 = Methodref #3.#23 // com/keanu/io/study/concurrency/VolatileDemo.\"\u003cinit\u003e\":()V #5 = Methodref #3.#26 // com/keanu/io/study/concurrency/VolatileDemo.incr:()V #6 = Class #27 // java/lang/Object #7 = Utf8 i #8 = Utf8 I #9 = Utf8 \u003cinit\u003e #10 = Utf8 ()V #11 = Utf8 Code #12 = Utf8 LineNumberTable #13 = Utf8 LocalVariableTable #14 = Utf8 this #15 = Utf8 Lcom/keanu/io/study/concurrency/VolatileDemo; #16 = Utf8 incr #17 = Utf8 main #18 = Utf8 ([Ljava/lang/String;)V #19 = Utf8 args #20 = Utf8 [Ljava/lang/String; #21 = Utf8 SourceFile #22 = Utf8 VolatileDemo.java #23 = NameAndType #9:#10 // \"\u003cinit\u003e\":()V #24 = NameAndType #7:#8 // i:I #25 = Utf8 com/keanu/io/study/concurrency/VolatileDemo #26 = NameAndType #16:#10 // incr:()V #27 = Utf8 java/lang/Object { volatile int i; descriptor: I flags: ACC_VOLATILE public com.keanu.io.study.concurrency.VolatileDemo(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"\u003cinit\u003e\":()V 4: aload_0 5: iconst_0 6: putfield #2 // Field i:I 9: return LineNumberTable: line 3: 0 line 5: 4 LocalVariableTable: Start Length Slot Name Signature 0 10 0 this Lcom/keanu/io/study/concurrency/VolatileDemo; public void incr(); descriptor: ()V flags: ACC_PUBLIC Code: stack=3, locals=1, args_size=1 0: aload_0 1: dup 2: getfield #2 // Field i:I 5: iconst_1 6: iadd 7: putfield #2 // Field i:I 10: return LineNumberTable: line 8: 0 line 9: 10 LocalVariableTable: Start Length Slot Name Signature 0 11 0 this Lcom/keanu/io/study/concurrency/VolatileDemo; public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=1, args_size=1 0: new #3 // class com/keanu/io/study/concurrency/VolatileDemo 3: dup 4: invokespecial #4 // Method \"\u003cinit\u003e\":()V 7: invokevirtual #5 // Method incr:()V 10: return LineNumberTable: line 12: 0 line 13: 10 LocalVariableTable: Start Length Slot Name Signature 0 11 0 args [Ljava/lang/String; } SourceFile: \"VolatileDemo.java\" ACC_VOLATILE 标志被定义在 JVM 源码的 accessFlags.hpp 中。 // accessFlags.hpp bool is_volatile () const { return (_flags \u0026 JVM_ACC_VOLATILE) != 0; } // bytecodeInterpreter.cpp // 存储变量时，判断是否被 volatile 修饰 if (cache -\u003e is_volatile()) { // 判断数据类型，根据不同的数据类型执行不同的方法 if (tos_type == itos) { // int 类型 obj -\u003e release_int_field_put(field_offset, STACK_INT(-1)); } else if (tos_type == atos) { // obj 对象类型 VERIFY_OOP(STACK_OBJECT(-1)); obj -\u003e release_obj_field_put(field_offset, STACK_OBJECT(-1)); OrderAccess::release_store(\u0026BYTE_MAP_BASE[(uintptr_t)obj \u003e\u003e CardTableModRefBS::card_shift], 0); } else if (tos_type == btos) { // byte 类型 obj -\u003e release_byte_field_put(field_offset, STACK_INT(-1)); } else if (tos_type == ltos) { // long 类型 obj -\u003e release_long_field_put(field_offset, STACK_LONG(-1)); } // ... char, short, float, double 省略 // 执行完毕后，执行下面这个方法 OrderAccess::storeload(); } // oop.inline.cpp // release_int_field_put 方法在此文件中 inline void oopDesc::release_int_field_put(int offset, jint contents) { OrderAccess::release_store(int_field_addr(offset), contents); } // release_store 方法在 orderAccess.hpp 中定义 // orderAccess.hpp static void release_store(volatile jint* p, jint v); //还有对其他数据类型的定义 // 具体的实现根据不同的操作系统CPU进行实现 Linux, Windows.. 等等 CPU // 例如：orderAccess_linux_x86.inline.hpp inline void OrderAccess::release_store(volatile jint* p, j","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-volatile/:1:0","tags":["Java"],"title":"Volatile 学习总结","uri":"/zh-cn/2021/10/java-volatile/"},{"categories":["Programming"],"content":"volatile 原子性问题 volatile 变量的复合操作是无法保证原子性问题的。为什么呢？ 例如： package com.keanu.io.study.concurrency; public class VolatileDemo { volatile int i = 0; public void incr() { i++; } public static void main(String[] args) { new VolatileDemo().incr(); } } 被 JVM 编译之后（使用 javap -c 指令查看字节码）： public class com.keanu.io.study.concurrency.VolatileDemo { volatile int i; public com.keanu.io.study.concurrency.VolatileDemo(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"\u003cinit\u003e\":()V 4: aload_0 5: iconst_0 6: putfield #2 // Field i:I 9: return public void incr(); Code: 0: aload_0 1: dup 2: getfield #2 // Field i:I 5: iconst_1 6: iadd 7: putfield #2 // Field i:I 10: return public static void main(java.lang.String[]); Code: 0: new #3 // class com/keanu/io/study/concurrency/VolatileDemo 3: dup 4: invokespecial #4 // Method \"\u003cinit\u003e\":()V 7: invokevirtual #5 // Method incr:()V 10: return } 可以看到，编译之后的指令中，i++（复合操作） 的操作分成了 3步，以上代码的 17，19，20 行。 getfield iadd putfield 当有多个线程同时执行时，有可能同一时间有多个线程同时执行了 getfield 指令，可能就会有一个线程拿到的是旧值，这就造成了原子性问题。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-volatile/:2:0","tags":["Java"],"title":"Volatile 学习总结","uri":"/zh-cn/2021/10/java-volatile/"},{"categories":["Programming"],"content":"如何解决原子性问题 可以通过 synchronized 关键字来解决，避免线程并行执行。synchronized 实现原理可以参照这篇文章：Synchronized关键字 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-volatile/:3:0","tags":["Java"],"title":"Volatile 学习总结","uri":"/zh-cn/2021/10/java-volatile/"},{"categories":["Programming"],"content":"关于 Java 回收的文章大同小异，我将我查阅的各种资料整合了一下，取文章中写的好的部分以及自我总结，写出这篇文章。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:0:0","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Programming"],"content":"Java 堆空间的基本结构 上图的 Eden 区和 Survivor From 区、Survivor To 区都属于新生代，Tenured 区属于老年代，在大部分情况，对象首先会在 Eden 区域分配，在第一次新生代垃圾回收（Minor GC）后，如果对象还存活，则该对象会进入 Survivor To 区，并且年龄会加1（第一次从 Eden 到 Survivor 区时年龄是1），当年龄到达一定程度时（默认为 15 岁，但是不一定必须到达 15 岁才会进入老年代区），对象会被晋升到老年代中，对象晋升到老年代的年龄阀值，可以通过设置参数 -XX:MaxTenuringThreshold 来控制。经过这次 GC 之后，Eden 区 和 From 区已经被清空，这时候，From 和 To 会交换他们的角色，也就是说此时新的 Survivor To 区就是 GC 之前的 Survivor From 区，新的 Survivor From 区就是 GC 之前的 Survivor To 区。Minor GC 会一直重复这个过程，直到 Survivor To 区被填满，To 区被填满之后，会将所有对象移动到老年代中。 堆内存常见的分配策略： 对象优先分配在 Eden 区 大对象直接进入老年代 长期存活的对象将进入老年代 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:1:0","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Programming"],"content":"Java 垃圾收集算法 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:2:0","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Programming"],"content":"标记 - 清除算法 该算法首先标记出需要回收的对象，在标记完成后统一回收所有被标记的对象。该算法是垃圾回收最基础的算法，后续的算法都是对其不足进行改进得到的。它会带来两个很明显的问题： 效率问题 空间浪费问题（标记清除后会产生大量不连续的碎片，导致大量空间无法使用） ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:2:1","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Programming"],"content":"复制算法 将堆内存分为大小相同的两块，每次只使用一块。这块内存使用完后，将还存活的对象复制到另一块内存中，然后把使用的空间一次全部清理，这样每次回收都只对内存的一半进行回收。 这样也会有一定的问题，就好比我们买了200平的房子，却只能使用100平，这就造成了使用空间的缩小。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:2:2","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Programming"],"content":"标记 - 整理算法 针对老年代特点特出的一种标记算法，过程与“标记 - 清除”算法一样，但是标记之后不是直接对可回收对象进行回收，而是让所有存活对象向一端移动，然后清理掉存活对象端边界以外的内存。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:2:3","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Programming"],"content":"分代收集算法 问题：HotSpot 为什么要分为新生代和老年代？ 根据对象存活周期的不同将内存分为几块（一般将 Java 堆分为新生代和老年代），这样就可以根据各年代的特点来选择合适的垃圾收集算法。 比如在新生代中，每次垃圾收集都会有大量的对象死去，所以我们可以选择复制算法，只需要付出少量对象的复制成本则可以完成每次垃圾收集。而老年代中对象的存活几率都是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择 “标记 - 清除” 或者 “标记 - 整理” 算法进行垃圾收集。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:2:4","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Programming"],"content":"垃圾收集器 图片来源：读书笔记—深入理解Java虚拟机1 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:3:0","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Programming"],"content":"新生代串行收集器 - Serial 串行收集器主要有两个特点：1、使用单线程进行垃圾回收；2、独占式的垃圾回收。 在串行收集器进行垃圾回收时，Java 应用程序中的线程都需要暂停，等待垃圾回收完成，这样就会造成较差的用户体验。但是串行收集器仍然是一个成熟的、经过长时间生产环境考验的极为高效的收集器。 新生代串行收集器采用复制算法，实现相对简单，并且没有线程切换的开销。在 HotSpot 虚拟机中，使用 -XX:+UseSerialGC 参数可以指定新生代串行收集器和老年代串行收集器。当 JVM 在 Client 模式下运行时，默认使用新生代串行收集器。一次新生代串行收集器的工作输出日志类似于下（使用 -XX:PrintGCDetails 开关）： [GC [DefNew: 3468K-\u003e150K(9216K), 0.0028638 secs][Tenured: 1562K-\u003e1712K(10240K), 0.0084220 secs] 3468K-\u003e1712K(19456K), [Perm : 377K-\u003e377K(12288K)], 0.0113816 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 它显示了垃圾回收之前新生代的占用内存和垃圾回收后的占用内存，以及垃圾回收的时间。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:3:1","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Programming"],"content":"新生代并行收集器 - ParNew 它是新生代串行收集器的多线程版本，垃圾回收时也会暂停 Java 应用程序的线程。它除了使用多线程处理垃圾回收外，其他的功能与 Serial 收集器一样。在单 CPU 的环境下，ParNew 收集器的表现不会比 Serial 更优秀。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:3:2","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Programming"],"content":"Parallel Scavenge 收集器 Parallel Scavenge 收集器也是使用复制算法的多线程垃圾收集器，它看上去几乎和 ParNer 一模一样。**但是 Parallel Scavenge 收集器的关注点是吞吐量（高效率的利用 CPU），吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。而 CMS 等垃圾收集器关注的更多的是用户线程的停顿时间，提高用户体验。**Parallel Scavenge 收集器提供了很多参数供用户找到最适合的停顿时间或最大的吞吐量。 -XX:UseParallelGC // 使用 Parrallel 收集器（新生代），老年代使用串行收集器 -XX:UseParallelOldGC // 使用 Parallel 收集器，老年代并行 此收集器中，新生代采用复制算法，老年代采用“标记-整理”算法 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:3:3","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Programming"],"content":"老年代串行收集器 - Serial Old 老年代串行收集器是 Serial 收集器的老年代版本，同样是单线程，但是它使用标记-整理算法。他也是一个串行的、独占式的垃圾回收器。由于老年代垃圾回收通常会使用比新生代垃圾回收更长的时间，因此，在堆空间较大的应用程序中，一旦老年代串行收集器启动，应用程序很可能会因此停顿几秒甚至更长时间。但是Serial Old 收集器可以和多种新生代收集器配合使用，而且可以作为 CMS 收集器的备用收集器。可以通过参数 -XX:+UseSerialGC 将新生代和老年代都使用串行收集器，使用 -XX:UseParallelOldGC 设置新生代和老年代都使用并行收集器。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:3:4","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Programming"],"content":"Parallel Old 收集器 **Parallel Scavenge 收集器的老年代版本。**该收集器采用”标记-整理“算法。注重吞吐量以及 CPU 资源的场合，都可以优先考虑 Parallel Scavenge 和 Parallel Old 收集器。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:3:5","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Programming"],"content":"CMS 收集器 CMS (Concurrent Mark Sweep) 收集器是一种以获取最短回收停顿时间为目标的收集器，它非常符合网站或者 B/S 系统的服务端上的 Java 应用等重视响应速度的场景。从名字上可以看出，它是基于 “标记-清除”算法实现的。 CMS 收集器的整个工作流程为以下 4 个步骤： 初始标记：暂停所有其他线程，标记 GC Roots 能直接关联的对象，速度很快。 并发标记：同时开启 GC 线程和用户线程，用闭包结构去记录可达对象。但是这个阶段结束后，并不能保证这个闭包包含所有的可达对象，因为用户线程可能同时会更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个阶段就是 GC Roots Tracing 过程，记录发生引用更新的地方。 重新标记：修正并发标记期间发生引用变化的那一部分对象。这一阶段的停顿时间会比初始标记阶段的时间稍长，但远远比并发标记的时间短。 并发清除：开启用户线程，同时 GC 线程对未标记的区域进行清除。 优点：并发，低停顿 缺点： 1、当次收集无法处理并发标记时用户线程产生的新的垃圾。 2、因为使用 “标记-清除” 算法，所以会产生很多内存空间碎片，导致当前堆中老年代空间有剩余，但是无法找到足够大的连续空间来分配当前对象，这样会提前触发一次 Full GC。 CMS 垃圾收集器的优化 -XX:ParallelCMSThreads：手动设置 CMS 的线程数量。CMS 默认启动的线程是 (ParallelGCThreads+3)/4) ，其中 ParallelGCThreads 是新生代并行收集器的线程数量。 -XX:CMSInitiatingOccupancyFraction：CMS 收集器进行垃圾回收的阀值（当前堆内存的使用率阀值），默认为 68，也就是说当堆内存的使用率达到 68% 时，会执行一次 CMS 回收。如果应用程序内内存增长很快，在 CMS 执行过程中，已经出现了内存不足的情况（用户线程会并行执行），就会导致 CMS 回收失败，JVM 将启动老年代串行收集器进行垃圾回收。这样会造成线程的停顿，影响用户体验，这时可以将 -XX:CMSInitiatingOccupancyFraction 调小。如果应用程序的内存增长缓慢的话，可以适当调大这个阀值，可以有效的降低 CMS 的触发频率 -XX:+UseCMSCompactAtFullCollection：因为 CMS 采用 “标记-清除” 算法，会造成大量内存碎片，这样会导致无法分配较大的对象，而触发 Full GC，这很影响系统性能。设置此参数可以使 CMS 在垃圾收集完成后，进行一次内存碎片整理（内存碎片整理不是并发进行的）。可以使用 -XX:CMSFullGCsBeforeCompaction 参数来设定进行多少次 CMS 回收后，进行一次内存压缩。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:3:6","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Programming"],"content":"G1 收集器 G1 GC 是 JDK 7 的新特性之一，它的目标是作为一款服务器的垃圾收集器。所以它在吞吐量和停顿控制上，都要优于 CMS。 以下引用自 JVM 七种垃圾收集器 G1 (Garbage First) 的各代存储地址是不连续的，每一代都使用了 n 个不连续的大小相同的 region， 每个 region 占有一块连续的虚拟内存地址。 G1 跟踪各个 Region 里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。 避免全堆扫描 多个 Region 之前的对象可能会有引用关系，在做可达性分析时需要扫描整个堆才能保证准确性，这显然降低了 GC 效率。 为避免全堆扫描，虚拟机为 G1 中每个 Region 维护了一个与之对应的 Remembered Set。虚拟机发现程序在对Reference类型的数据进行写操作时，会产生一个Write Barrier 暂时中断写操作，检查 Reference 引用的对象是否处于不同的 Region 之中（在分代的例子中就是检查是否老年代中的对象引用了新生代中的对象），如果是，便通过 CardTable 把相关引用信息记录到被引用对象所属的Region的 Remembered Set 之中。当进行内存回收时，在GC根节点的枚举范围中加入 Remembered Set 即可保证不对全堆扫描也不会有遗漏。 G1 的运作步骤 初始标记（Initial Marking） 并发标记（Concurrent Marking） 最终标记（Final Marking） 筛选回收（Live Data Counting and Evacuation） 特点 空间整合：整体来看是基于“标记 - 整理”算法实现的收集器，从局部（两个 Region 之间）上来看是基于“复制”算法实现的，这意味着运行期间不会产生内存空间碎片。 可预测的停顿：能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒。 以上引用自 JVM 七种垃圾收集器 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:3:7","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Programming"],"content":"GC 相关参数设置 可以适当使用这些参数对 GC 进行调优。 1、输出 GC 日志 -XX:+PrintGCDetails // 输出 GC 日志 -XX:+DisableExplicitGC // 禁用显示 GC 2、串行 GC 相关设置 -XX:+UseSerialGC // 指定新生代和老年代都使用串行收集器（Client模式默认值） -XX:+SurvivorRatio // 设置 eden 区大小和 survivor 区大小的比例，默认为8 -XX:+PretenureSizeThreshold // 设置大对象直接进入老年代的阈值。当对象的大小超过这个值时，将直接在老年代分配。 -XX:MaxTenuringThreshold // 设置对象进入老年代的年龄的最大值。每一次 Minor GC 后，对象年龄就加 1。任何大于这个年龄的对象，一定会进入老年代。 3、并行 GC 参数设置 -XX:+UseParNewGC // 使用 ParNew + Serial Old 组合进行垃圾回收（不推荐） -XX:+UseParallelGC // 使用 Parallel Scavenge 和 Serial Old 组合进行回收 -XX:+UseParallelOldGC // Parallel Scavenge + Parallel Old 收集组合进行垃圾回收 -XX:ParallelGCThreads //并行收集器工作时的线程数量，在 CPU 数量小于8个时，ParallelGCThreads等于 CPU 数量；如果大于8个，ParalellGCThreads 的值等于 3+[5*CPU_Count]/8]； -XX:+MaxGCPauseMills // 设置最大垃圾收集停顿时间 -XX:+GCTimeRatio // 设置吞吐量大小（0 - 100之间的整数）垃圾收集时间不会超过 1/(1+n) -XX:+UseAdaptiveSizePolicy // 打开自适应 GC 策略 4、CMS 收集器相关参数设置 -XX:+UseConcMarkSweepGC // 新生代使用并行收集器，老年代使用 CMS + 串行收集器 -XX:ParallelCMSThreads // 手动设定 CMS 的线程数量 -XX:CMSInitiatingOccupancyFraction // CMS 回收触发阀值（当前堆内存的使用率）默认为68（68%） -XX:+UseCMSCompactAtFullCollection // CMS 垃圾回收完成后，进行一次内存碎片整理 -XX:CMSFullGCsBeforeCompaction // 多少次 CMS 垃圾回收后，进行一次内存整理（压缩） -XX:+CMSClassUnloadingEnabled // 允许对类元数据进行回收 -XX:+CMSParallelRemarkEndable // 启用并行重标记 -XX:CMSInitatingPermOccupancyFraction // 当永久区占用率达到这一百分比后，启动 CMS 回收（需要开启 - XX:+CMSClassUnloadingEnabled） -XX:UseCMSInitatingOccupancyOnly // 只有到达阀值的时候，才进行 CMS 回收 -XX:+CMSIncrementalMode // 使用增量模式，适用于单 CPU 5、G1 收集器相关参数设置参数 -XX:+UseG1GC // 使用 G1 收集器 -XX:+UnlockExperimentalVMOptions // 允许使用实验性参数 -XX:+MaxGCPauseMills // 设置垃圾收集最大停顿时间 -XX:+GCPauseIntervalMills // 设置停顿间隔时间 基于对 JVM 垃圾回收器的工作原理以及程序设计的了解，希望大家都能找出适合自己的最优优化方案。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:4:0","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Programming"],"content":"对于几个问题的解答 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:5:0","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Programming"],"content":"对象死亡的判断 堆中几乎存放着所有的实例对象，所以要了解垃圾回收器，首先要学会判断哪些对象已经死亡（不能再使用）。 JVM 有两种方法判断对象是否死亡： 引用计数法 给对象添加一个引用计数器，如果有一个地方引用它，计数器就加1，引用失效时，计数器减1。计数器值为0的对象就是不能再使用的。 这种方法实现简单，效率高，但是目前主流的虚拟机没有再使用这种方法了，因为它无法解决对象之间相互引用的的问题。 可达性分析法 此算法的基本思想就是通过一系列的称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，借点娑走过的路径叫做引用链，当一个对象到 GC Roots 没有任何引用链相连的话，就说明此对象是不可用的。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:5:1","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Programming"],"content":"Minor GC 和 Full GC 的区别 新生代 GC（Minor GC）：发生在新生代的垃圾收集操作，Minor GC 非常频繁，且一般速度也比较快。 Major GC / Full GC：发生在老年代的 GC，速度一般比 Minor GC 慢10倍以上。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:5:2","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Programming"],"content":"其他问题 Java 四种引用类型 ～ 强引用，软引用，弱引用，虚引用（虚引用与软引用和弱引用的区别，使用软引用的好处） 如何判断一个常量是废弃常量 如何判断一个类是无用的类 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:5:3","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Programming"],"content":"总结 来源于 JVM 七种垃圾收集器 收集器 串行、并行or并发 新生代/老年代 算法 目标 适用场景 Serial 串行 新生代 复制算法 响应速度优先 单CPU环境下的Client模式 Serial Old 串行 老年代 标记-整理 响应速度优先 单CPU环境下的Client模式、CMS的后备预案 ParNew 并行 新生代 复制算法 响应速度优先 多CPU环境时在Server模式下与CMS配合 Parallel Scavenge 并行 新生代 复制算法 吞吐量优先 在后台运算而不需要太多交互的任务 Parallel Old 并行 老年代 标记-整理 吞吐量优先 在后台运算而不需要太多交互的任务 CMS 并发 老年代 标记-清除 响应速度优先 集中在互联网站或B/S系统服务端上的Java应用 G1 并发 both 标记-整理+复制算法 响应速度优先 面向服务端应用 [参考链接] Java Garbage Collection Basics JVM Garbage Collectors Java Garbage Collection Algorithms SnailClimb JavaGuide - Java垃圾回收 JVM 垃圾回收器工作原理及使用实例介绍 JVM 七种垃圾收集器 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/java-garbage-collection/:6:0","tags":["Java","GC"],"title":"Java 垃圾收集器","uri":"/zh-cn/2021/10/java-garbage-collection/"},{"categories":["Cloud Native"],"content":"前提条件 一个 Linux 主机。Kubernetes 项目为基于 Debian 和 Red Hat 的 Linux 发行版提供了通用的说明。 每个机器至少 2GB 的内存。 至少 2 个 CPU 集群中所有机器之间的网络连接，公网或内网都可以。 每个节点由唯一的主机名，MAC 地址。 指定的端口在机器上是开放的。点击这里查看具体信息。 禁用 Swap。为了使 kubectl 正常工作，必须禁用 swap。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/kubenetes-on-centos/:1:0","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/zh-cn/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"让 iptables 能发现桥接网络的流量 确保 br_netfilter 模块被装载了。可以通过以下命令来完成： lsmod | grep br_netfilter # br_netfilter 22256 0 # bridge 151336 2 br_netfilter,ebtable_broute sudo modprobe br_netfilter 为了让 Linux 节点的 iptables 能正确的观测到桥接流量，需要保证 net.bridge.bridge-nf-call-iptables 被设置为1： sudo tee /etc/sysctl.d/kubernetes.conf\u003c\u003cEOF net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 EOF sudo sysctl --system ","date":"2021-10-02","objectID":"/zh-cn/2021/10/kubenetes-on-centos/:1:1","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/zh-cn/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"检查需要的端口 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/kubenetes-on-centos/:1:2","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/zh-cn/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"安装 Docker 参考：Install Docker Engine on CentOS ","date":"2021-10-02","objectID":"/zh-cn/2021/10/kubenetes-on-centos/:1:3","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/zh-cn/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"安装 Kubernetes ","date":"2021-10-02","objectID":"/zh-cn/2021/10/kubenetes-on-centos/:2:0","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/zh-cn/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"准备 Kubernetes 服务器 服务器类型 主机名 具体信息 Master 192.168.2.60 2 CPUs, 2GB Ram Worker 192.168.2.61 2 CPUs, 2GB Ram Worker 192.168.2.62 2 CPUs, 2GB Ram ","date":"2021-10-02","objectID":"/zh-cn/2021/10/kubenetes-on-centos/:2:1","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/zh-cn/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"安装 kubelet 和 kubeadm cat \u003c\u003cEOF | sudo tee /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\\$basearch enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg exclude=kubelet kubeadm kubectl EOF sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes sudo systemctl enable --now kubelet ","date":"2021-10-02","objectID":"/zh-cn/2021/10/kubenetes-on-centos/:2:2","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/zh-cn/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"禁用 SELinux 和 Swap # Set SELinux in permissive mode (effectively disabling it) sudo setenforce 0 sudo sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config # Disable swap sudo sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab sudo swapoff -a ","date":"2021-10-02","objectID":"/zh-cn/2021/10/kubenetes-on-centos/:2:3","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/zh-cn/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"配置防火墙 启用 Master 节点端口: sudo firewall-cmd --add-port={6443,2379-2380,10250,10251,10252,5473,179,5473}/tcp --permanent sudo firewall-cmd --add-port={4789,8285,8472}/udp --permanent sudo firewall-cmd --reload 启用 Worker 节点端口: sudo firewall-cmd --add-port={10250,30000-32767,5473,179,5473}/tcp --permanent sudo firewall-cmd --add-port={4789,8285,8472}/udp --permanent sudo firewall-cmd --reload ","date":"2021-10-02","objectID":"/zh-cn/2021/10/kubenetes-on-centos/:3:0","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/zh-cn/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"验证安装是否成功 为了验证安装是否成功，我们准备用 kubeadm 创建一个 cluster。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/kubenetes-on-centos/:4:0","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/zh-cn/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"初始化 Kubernetes Control Plane (K8s 控制平面) 首先，向 /etc/hosts 中添加下面的主机名： 192.168.2.60 k8s-master01 k8s-master01.torres.com 然后运行以下命令来初始化 master 节点的 control plane： # (Optional) You can run this commands to verify the connection with gcr.io sudo kubeadm config images pull # Init Control plane sudo kubeadm init --control-plane-endpoint=k8s-master01.torres.com --node-name=k8s-master01 --upload-certs 然后可以看到以下的日志： [init] Using Kubernetes version: v1.21.1 [preflight] Running pre-flight checks [WARNING Firewalld]: firewalld is active, please ensure ports [6443 10250] are open or your cluster may not function correctly [WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\". Please follow the guide at https://kubernetes.io/docs/setup/cri/ [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using 'kubeadm config images pull' [certs] Using certificateDir folder \"/etc/kubernetes/pki\" [certs] Generating \"ca\" certificate and key [certs] Generating \"apiserver\" certificate and key [certs] apiserver serving cert is signed for DNS names [k8s-master01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local localhost.localdomain] and IPs [10.96.0.1 192.168.2.60] [certs] Generating \"apiserver-kubelet-client\" certificate and key [certs] Generating \"front-proxy-ca\" certificate and key [certs] Generating \"front-proxy-client\" certificate and key [certs] Generating \"etcd/ca\" certificate and key [certs] Generating \"etcd/server\" certificate and key [certs] etcd/server serving cert is signed for DNS names [localhost localhost.localdomain] and IPs [192.168.2.60 127.0.0.1 ::1] [certs] Generating \"etcd/peer\" certificate and key [certs] etcd/peer serving cert is signed for DNS names [localhost localhost.localdomain] and IPs [192.168.2.60 127.0.0.1 ::1] [certs] Generating \"etcd/healthcheck-client\" certificate and key [certs] Generating \"apiserver-etcd-client\" certificate and key [certs] Generating \"sa\" key and public key [kubeconfig] Using kubeconfig folder \"/etc/kubernetes\" [kubeconfig] Writing \"admin.conf\" kubeconfig file [kubeconfig] Writing \"kubelet.conf\" kubeconfig file [kubeconfig] Writing \"controller-manager.conf\" kubeconfig file [kubeconfig] Writing \"scheduler.conf\" kubeconfig file [kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\" [kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\" [kubelet-start] Starting the kubelet [control-plane] Using manifest folder \"/etc/kubernetes/manifests\" [control-plane] Creating static Pod manifest for \"kube-apiserver\" [control-plane] Creating static Pod manifest for \"kube-controller-manager\" [control-plane] Creating static Pod manifest for \"kube-scheduler\" [etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\" [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s [apiclient] All control plane components are healthy after 13.004835 seconds [upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace [kubelet] Creating a ConfigMap \"kubelet-config-1.21\" in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Storing the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace [upload-certs] Using certificate key: b8cb86fb2bd01029d07cd1c67a6ae9ca358655595cef1cc7bec5253b64a81037 [mark-control-plane] Marking the node localhost.localdomain as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers] [mark-control-plane] Marking the node localhos","date":"2021-10-02","objectID":"/zh-cn/2021/10/kubenetes-on-centos/:4:1","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/zh-cn/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"验证 运行以下指令来验证集群是否初始化成功： kubectl cluster-info Kubernetes control plane is running at https://k8s-master01:6443 CoreDNS is running at https://k8s-master01:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. 如果你还想看有哪些节点： kubectl get nodes NAME STATUS ROLES AGE VERSION localhost.localdomain NotReady control-plane,master 3m15s v1.21.1 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/kubenetes-on-centos/:4:2","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/zh-cn/2021/10/kubenetes-on-centos/"},{"categories":["Programming"],"content":"Hello Golang Golang 是由 Google 开发并开源出来的一种编程语言，Kubernetes 就是由 Go 主要开发的，由此可见 Go 在云原生开发中的重要地位。在这里我们主要介绍 Golang 的基础知识，例如各种语法，数据结构，以及一些 Tips。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/golang-fundamentals/:1:0","tags":["Golang"],"title":"Golang 基础知识","uri":"/zh-cn/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"声明和赋值 Go 中声明变量和给变量赋值的方法和 JavaScript 比较相似。如下： // var 是声明变量的关键字，如果只声明变量而不给它赋值 // 则该变量会被赋值为该类型的零值（zero value） var num int // := 是声明并赋值的操作符 // 其工作流程为： // 1. 声明一个名为 num 的变量 // 2. 将 10 赋值给变量 num num := 10 但是要注意的是，每个类型的零值不相同，比如说 int 的零值为 0，浮点类型的零值为 0.0，而 string 的零值为空字符串：\"\"… 如 struct 或者指针类型的变量，零值为 nil。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/golang-fundamentals/:2:0","tags":["Golang"],"title":"Golang 基础知识","uri":"/zh-cn/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"基础数据类型 Go 的基础数据类型和其他的编程语言相似，在这里我们介绍一下 Go 中的整型、字符串、浮点型、布尔型等： ","date":"2021-10-02","objectID":"/zh-cn/2021/10/golang-fundamentals/:3:0","tags":["Golang"],"title":"Golang 基础知识","uri":"/zh-cn/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"整型 有符号整型： 类型 大小 范围 int8 8 bits -128 to 127 int16 16 bits -215 to 215 -1 int32 32 bits -231 to 231 -1 int64 64 bits -263 to 263 -1 int 取决于平台 取决于平台 int 的大小取决于平台，在32位系统中它是32位的，而在64位系统中，它是64位。 无符号整型： 类型 大小 范围 uint8 8 bits 0 to 255 uint16 16 bits 0 to 216 -1 uint32 32 bits 0 to 232 -1 uint64 64 bits 0 to 264 -1 uint 取决于平台 取决于平台 uint 和 int 的大小一样取决于所在的平台。 提示：当你使用 integer 类型的值时，除非你有更好的原因去使用无符号整型或者带位数的整型类型，否则请使用 int . Golang 中还有两个额外的类型可以表示整型： 类型 表示为 byte uint8 rune int32 在 Go 中，rune 和 byte是用来区分字符和整型类型的。Go 中没有 char 类型，它用 rune 和 byte 来表示字符（但是它们本质上都是整数类型）： var firstLetter = 'A' // Type inferred as `rune` (Default type for character values) var lastLetter byte = 'Z' 而 byte 可以转换成 ASCII 码中对应的数字，如 firstLetter 可以转换成 65。rune 变量能转换为 Unicode 中对应的编码。 package main import \"fmt\" func main() { var myByte byte = 'a' var myRune rune = '♥' fmt.Printf(\"%c = %d and %c = %U\\n\", myByte, myByte, myRune, myRune) } # Output a = 97 and ♥ = U+2665 可以看到 a 被转成了 97，Unicode 值 ‘♥’ 被转换成了对应的 Unicode 码：U+2665。U 代表 Unicode，后面的数字则是16进制的整数。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/golang-fundamentals/:3:1","tags":["Golang"],"title":"Golang 基础知识","uri":"/zh-cn/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"浮点型 浮点类型的数字包括两种： float32：在内存中占用 32 bits，以单精度浮点格式存储值。 float64：在内存中占用 64 bits，以双精度浮点格式存储值。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/golang-fundamentals/:3:2","tags":["Golang"],"title":"Golang 基础知识","uri":"/zh-cn/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"集合类型 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/golang-fundamentals/:4:0","tags":["Golang"],"title":"Golang 基础知识","uri":"/zh-cn/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"数组 在 Go 中，数组是固定长度的数据类型，包含相同类型元素的连续内存块。定义数组的代码如下： // 声明一个长度为5的数组，默认初始化每个元素为0（参考上面说到的零值） var arr [5]int // 声明并初始化一个长度为5的数组 arr := [5]int{1,2,3,4,5} // 声明一个int数组，Go会基于初始化元素的个数来决定其长度 arr := [...]int{1,2,3} // 声明一个长度为5的int数组，但是只初始化指定位置的元素 arr := [5]int{1: 20, 3: 40} 注意： 数组只要被声明之后，就无法再更改其长度和类型了。 在 functions 之间传递数组是非常昂贵的，如果是在需要传递数组，可以考虑传递它的指针。 声明一个一百万个元素的 int 数组，在64位操作系统上会占用 8MB 内存。 而在 function 之间传递时，每调用一次 function，都会在栈中分配一个 8MB 的空间给这个数组。 而传递这个数组的指针则会更高效，指针对象只会占用8个字节空间。 ","date":"2021-10-02","objectID":"/zh-cn/2021/10/golang-fundamentals/:4:1","tags":["Golang"],"title":"Golang 基础知识","uri":"/zh-cn/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"Slice ","date":"2021-10-02","objectID":"/zh-cn/2021/10/golang-fundamentals/:4:2","tags":["Golang"],"title":"Golang 基础知识","uri":"/zh-cn/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"Map ","date":"2021-10-02","objectID":"/zh-cn/2021/10/golang-fundamentals/:4:3","tags":["Golang"],"title":"Golang 基础知识","uri":"/zh-cn/2021/10/golang-fundamentals/"}]