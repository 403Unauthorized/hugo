[{"categories":["Kubernetes"],"content":"Prerequisite A compatible Linux host. The Kubernetes project provides generic instructions for Linux distributions based on Debian and Red Hat, and those distributions without a package manager. 2 GB or more of RAM per machine (any less will leave little room for your apps). 2 CPUs or more. Full network connectivity between all machines in the cluster (public or private network is fine). Unique hostname, MAC address, and product_uuid for every node. See here for more details. Certain ports are open on your machines. See here for more details. Swap disabled. You MUST disable swap in order for the kubelet to work properly. ","date":"2021-10-02","objectID":"/hugo/2021/10/kubenetes-on-centos/:1:0","tags":["Cloud Native","Kubernetes"],"title":"Kubenetes on Centos","uri":"/hugo/2021/10/kubenetes-on-centos/"},{"categories":["Kubernetes"],"content":"Letting iptables see bridged traffic Make sure that the br_netfilter module is loaded. This can be done by running lsmod | grep br_netfilter. To load it explicitly call sudo modprobe br_netfilter. lsmod | grep br_netfilter # br_netfilter 22256 0 # bridge 151336 2 br_netfilter,ebtable_broute sudo modprobe br_netfilter As a requirement for your Linux Node’s iptables to correctly see bridged traffic, you should ensure net.bridge.bridge-nf-call-iptables is set to 1 in your sysctl config. sudo tee /etc/sysctl.d/kubernetes.conf\u003c\u003cEOF net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 EOF sudo sysctl --system ","date":"2021-10-02","objectID":"/hugo/2021/10/kubenetes-on-centos/:1:1","tags":["Cloud Native","Kubernetes"],"title":"Kubenetes on Centos","uri":"/hugo/2021/10/kubenetes-on-centos/"},{"categories":["Kubernetes"],"content":"Check Required Ports ","date":"2021-10-02","objectID":"/hugo/2021/10/kubenetes-on-centos/:1:2","tags":["Cloud Native","Kubernetes"],"title":"Kubenetes on Centos","uri":"/hugo/2021/10/kubenetes-on-centos/"},{"categories":["Kubernetes"],"content":"Install Docker Refer: Install Docker Engine on CentOS ","date":"2021-10-02","objectID":"/hugo/2021/10/kubenetes-on-centos/:1:3","tags":["Cloud Native","Kubernetes"],"title":"Kubenetes on Centos","uri":"/hugo/2021/10/kubenetes-on-centos/"},{"categories":["Kubernetes"],"content":"Install Kubernetes ","date":"2021-10-02","objectID":"/hugo/2021/10/kubenetes-on-centos/:2:0","tags":["Cloud Native","Kubernetes"],"title":"Kubenetes on Centos","uri":"/hugo/2021/10/kubenetes-on-centos/"},{"categories":["Kubernetes"],"content":"Prepare Kubernetes Servers Server Type Host Name Specs Master 192.168.2.60 2 CPUs, 2GB Ram Worker 192.168.2.61 2 CPUs, 2GB Ram Worker 192.168.2.62 2 CPUs, 2GB Ram Here I used a VM which has 2 CPUs and 4GB Ram for master node. ","date":"2021-10-02","objectID":"/hugo/2021/10/kubenetes-on-centos/:2:1","tags":["Cloud Native","Kubernetes"],"title":"Kubenetes on Centos","uri":"/hugo/2021/10/kubenetes-on-centos/"},{"categories":["Kubernetes"],"content":"Install kubeadm and kubectl cat \u003c\u003cEOF | sudo tee /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\\$basearch enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg exclude=kubelet kubeadm kubectl EOF sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes sudo systemctl enable --now kubelet ","date":"2021-10-02","objectID":"/hugo/2021/10/kubenetes-on-centos/:2:2","tags":["Cloud Native","Kubernetes"],"title":"Kubenetes on Centos","uri":"/hugo/2021/10/kubenetes-on-centos/"},{"categories":["Kubernetes"],"content":"Disable SELinux and Swap # Set SELinux in permissive mode (effectively disabling it) sudo setenforce 0 sudo sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config # Disable swap sudo sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab sudo swapoff -a ","date":"2021-10-02","objectID":"/hugo/2021/10/kubenetes-on-centos/:2:3","tags":["Cloud Native","Kubernetes"],"title":"Kubenetes on Centos","uri":"/hugo/2021/10/kubenetes-on-centos/"},{"categories":["Kubernetes"],"content":"Configure Firewall Enable Master Node Ports: sudo firewall-cmd --add-port={6443,2379-2380,10250,10251,10252,5473,179,5473}/tcp --permanent sudo firewall-cmd --add-port={4789,8285,8472}/udp --permanent sudo firewall-cmd --reload Enable Worker Node Ports: sudo firewall-cmd --add-port={10250,30000-32767,5473,179,5473}/tcp --permanent sudo firewall-cmd --add-port={4789,8285,8472}/udp --permanent sudo firewall-cmd --reload ","date":"2021-10-02","objectID":"/hugo/2021/10/kubenetes-on-centos/:3:0","tags":["Cloud Native","Kubernetes"],"title":"Kubenetes on Centos","uri":"/hugo/2021/10/kubenetes-on-centos/"},{"categories":["Kubernetes"],"content":"Verify the installation In order to verify whether the installation is successful, we are gonna create a cluster using kubeadm. ","date":"2021-10-02","objectID":"/hugo/2021/10/kubenetes-on-centos/:4:0","tags":["Cloud Native","Kubernetes"],"title":"Kubenetes on Centos","uri":"/hugo/2021/10/kubenetes-on-centos/"},{"categories":["Kubernetes"],"content":"Initialize Kubernetes Control Plane First of all, I added a host name to /etc/hosts , as below: 192.168.2.60 k8s-master01 k8s-master01.torres.com Then I run below commands to initialize the control plane on master node: # (Optional) You can run this commands to verify the connection with gcr.io sudo kubeadm config images pull # Init Control plane sudo kubeadm init --control-plane-endpoint=k8s-master01.torres.com --node-name=k8s-master01 --upload-certs Then you can see logs as follows: [init] Using Kubernetes version: v1.21.1 [preflight] Running pre-flight checks [WARNING Firewalld]: firewalld is active, please ensure ports [6443 10250] are open or your cluster may not function correctly [WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\". Please follow the guide at https://kubernetes.io/docs/setup/cri/ [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using 'kubeadm config images pull' [certs] Using certificateDir folder \"/etc/kubernetes/pki\" [certs] Generating \"ca\" certificate and key [certs] Generating \"apiserver\" certificate and key [certs] apiserver serving cert is signed for DNS names [k8s-master01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local localhost.localdomain] and IPs [10.96.0.1 192.168.2.60] [certs] Generating \"apiserver-kubelet-client\" certificate and key [certs] Generating \"front-proxy-ca\" certificate and key [certs] Generating \"front-proxy-client\" certificate and key [certs] Generating \"etcd/ca\" certificate and key [certs] Generating \"etcd/server\" certificate and key [certs] etcd/server serving cert is signed for DNS names [localhost localhost.localdomain] and IPs [192.168.2.60 127.0.0.1 ::1] [certs] Generating \"etcd/peer\" certificate and key [certs] etcd/peer serving cert is signed for DNS names [localhost localhost.localdomain] and IPs [192.168.2.60 127.0.0.1 ::1] [certs] Generating \"etcd/healthcheck-client\" certificate and key [certs] Generating \"apiserver-etcd-client\" certificate and key [certs] Generating \"sa\" key and public key [kubeconfig] Using kubeconfig folder \"/etc/kubernetes\" [kubeconfig] Writing \"admin.conf\" kubeconfig file [kubeconfig] Writing \"kubelet.conf\" kubeconfig file [kubeconfig] Writing \"controller-manager.conf\" kubeconfig file [kubeconfig] Writing \"scheduler.conf\" kubeconfig file [kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\" [kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\" [kubelet-start] Starting the kubelet [control-plane] Using manifest folder \"/etc/kubernetes/manifests\" [control-plane] Creating static Pod manifest for \"kube-apiserver\" [control-plane] Creating static Pod manifest for \"kube-controller-manager\" [control-plane] Creating static Pod manifest for \"kube-scheduler\" [etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\" [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s [apiclient] All control plane components are healthy after 13.004835 seconds [upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace [kubelet] Creating a ConfigMap \"kubelet-config-1.21\" in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Storing the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace [upload-certs] Using certificate key: b8cb86fb2bd01029d07cd1c67a6ae9ca358655595cef1cc7bec5253b64a81037 [mark-control-plane] Marking the node localhost.localdomain as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io","date":"2021-10-02","objectID":"/hugo/2021/10/kubenetes-on-centos/:4:1","tags":["Cloud Native","Kubernetes"],"title":"Kubenetes on Centos","uri":"/hugo/2021/10/kubenetes-on-centos/"},{"categories":["Kubernetes"],"content":"Verification We can run this command to verify the cluster we just created: kubectl cluster-info Kubernetes control plane is running at https://k8s-master01:6443 CoreDNS is running at https://k8s-master01:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. Also if you want to see the nodes: kubectl get nodes NAME STATUS ROLES AGE VERSION localhost.localdomain NotReady control-plane,master 3m15s v1.21.1 If you see the status of the nodes you created is not ready, you can check if all the pods in the node is RUNNING: kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-558bd4d5db-9szx5 0/1 Pending 0 7m31s kube-system coredns-558bd4d5db-lx7jv 0/1 Pending 0 7m31s kube-system etcd-localhost.localdomain 1/1 Running 0 7m36s kube-system kube-apiserver-localhost.localdomain 1/1 Running 0 7m36s kube-system kube-controller-manager-localhost.localdomain 1/1 Running 0 7m36s kube-system kube-proxy-2skgn 1/1 Running 0 7m31s kube-system kube-scheduler-localhost.localdomain 1/1 Running 0 7m38s The coredns is still Pending, so we have to install a network plugin to make the coredns work. ","date":"2021-10-02","objectID":"/hugo/2021/10/kubenetes-on-centos/:4:2","tags":["Cloud Native","Kubernetes"],"title":"Kubenetes on Centos","uri":"/hugo/2021/10/kubenetes-on-centos/"},{"categories":["Kubernetes"],"content":"Install network plugin - Calico kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml onfigmap/calico-config created customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/kubecontrollersconfigurations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created clusterrole.rbac.authorization.k8s.io/calico-node created clusterrolebinding.rbac.authorization.k8s.io/calico-node created daemonset.apps/calico-node created serviceaccount/calico-node created deployment.apps/calico-kube-controllers created serviceaccount/calico-kube-controllers created Warning: policy/v1beta1 PodDisruptionBudget is deprecated in v1.21+, unavailable in v1.25+; use policy/v1 PodDisruptionBudget poddisruptionbudget.policy/calico-kube-controllers created Then run following command to see the service: kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system calico-kube-controllers-78d6f96c7b-9kd5b 1/1 Running 0 6m57s kube-system calico-node-f8fsw 1/1 Running 0 6m57s kube-system coredns-558bd4d5db-9szx5 1/1 Running 0 14m kube-system coredns-558bd4d5db-lx7jv 1/1 Running 0 14m kube-system etcd-localhost.localdomain 1/1 Running 0 14m kube-system kube-apiserver-localhost.localdomain 1/1 Running 0 14m kube-system kube-controller-manager-localhost.localdomain 1/1 Running 0 14m kube-system kube-proxy-2skgn 1/1 Running 0 14m kube-system kube-scheduler-localhost.localdomain 1/1 Running 0 14m After the installation of Network Plugin (Calico), we can see coredns is Running, and there are another two pods for calico network plugin. Now, we are going to install Kubernetes Dashboard! ","date":"2021-10-02","objectID":"/hugo/2021/10/kubenetes-on-centos/:5:0","tags":["Cloud Native","Kubernetes"],"title":"Kubenetes on Centos","uri":"/hugo/2021/10/kubenetes-on-centos/"},{"categories":["Kubernetes"],"content":"Install Kubernetes Dashboard By default, the dashboar ui is not deployed, so we need to do it manually with following command: kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.2.0/aio/deploy/recommended.yaml # Then you can use this command to see the dashboard is running kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system calico-kube-controllers-78d6f96c7b-9kd5b 1/1 Running 0 9m41s kube-system calico-node-f8fsw 1/1 Running 0 9m41s kube-system coredns-558bd4d5db-9szx5 1/1 Running 0 17m kube-system coredns-558bd4d5db-lx7jv 1/1 Running 0 17m kube-system etcd-localhost.localdomain 1/1 Running 0 17m kube-system kube-apiserver-localhost.localdomain 1/1 Running 0 17m kube-system kube-controller-manager-localhost.localdomain 1/1 Running 0 17m kube-system kube-proxy-2skgn 1/1 Running 0 17m kube-system kube-scheduler-localhost.localdomain 1/1 Running 0 17m kubernetes-dashboard dashboard-metrics-scraper-856586f554-p7gxx 1/1 Running 0 44s kubernetes-dashboard kubernetes-dashboard-78c79f97b4-qs57f 1/1 Running 0 45s The yaml file above is a recommended config for production environment, it helps us to create service, service account, cluster role and deployment for kubernetes dashboard. You can access Dashboard using the kubectl command-line tool by running the following command: kubectl proxy This will start serving at localhost:8001 by default. Then you can access http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/ to see your dashboard. But there are some optional parameters for the command: kubectl proxy --address='192.168.2.60' --port=9001 --accept-hosts='^*$' --address: The IP address on which to serve on. -p --port: The port on which to run the proxy. Set to 0 to pick a random port. --accept-hosts: Regular expression for hosts that the proxy should accept. (使用正则表达式指定proxy应该接收的hosts) --api-prefix='/': Prefix to serve the proxied API under. For more details of the command, please use kubectl proxy --help. ","date":"2021-10-02","objectID":"/hugo/2021/10/kubenetes-on-centos/:6:0","tags":["Cloud Native","Kubernetes"],"title":"Kubenetes on Centos","uri":"/hugo/2021/10/kubenetes-on-centos/"},{"categories":["Kubernetes"],"content":"Kubernetes Dashboard When every pod of kubenetes-dashboard is running, then you can access the dashboard. Now you can see the dashboar login screen, but it requires authentication at login. So you need to find the Token or Kubeconfig to sign in with following commands: # See secret in kubernetes-dashboard namespace kubectl -n kubernetes-dashboard get secret NAME TYPE DATA AGE default-token-p7rgf kubernetes.io/service-account-token 3 27m kubernetes-dashboard-certs Opaque 0 27m kubernetes-dashboard-csrf Opaque 1 27m kubernetes-dashboard-key-holder Opaque 2 27m kubernetes-dashboard-token-8kjgr kubernetes.io/service-account-token 3 27m # Get details of token kubectl -n kubernetes-dashboard describe secret kubernetes-dashboard-token-8kjgr Name: kubernetes-dashboard-token-8kjgr Namespace: kubernetes-dashboard Labels: \u003cnone\u003e Annotations: kubernetes.io/service-account.name: kubernetes-dashboard kubernetes.io/service-account.uid: d54e2160-e9b0-444d-93fc-5d38f8fa61ef Type: kubernetes.io/service-account-token Data ==== ca.crt: 1066 bytes namespace: 20 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6ImNKX2pGTG9fUXE0cmk1cE5oUkpPYzVoald2TXFWN2QySHBEV1RlclNlMWcifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZC10b2tlbi04a2pnciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImQ1NGUyMTYwLWU5YjAtNDQ0ZC05M2ZjLTVkMzhmOGZhNjFlZiIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlcm5ldGVzLWRhc2hib2FyZDprdWJlcm5ldGVzLWRhc2hib2FyZCJ9.YbuWfZ3Qu9hjQTEVpuR7FxGrjboO8OpjqY4tE1O86v9UD9OilCbb330QRCNbTPcobLfXvFHRsJ4MVY2LHaCM1s2y2fpGE3dGPpPs2XcLJj2Aw3e_mJKHy9sZHtjfAG0cFgWKhyr_LTEuxk3_0pEVMKtuk2WeSqoo37ADhUjR92G7dK0TGkahkNzOH0-I_Yn40oZn9wA9w0r4DCGd5q8s2c5piHd6jGOuRX-7_UKgVfc6GYkRngAsrVZTnqfZkjv0LoH8Egkmu2X3CRvMz4JrlyhScTPZ77Uck0PXVklU57tK1PdgPIcczlvVJtr4avyBZsS5Y9j5zjm7sSDvPMeuJQ Then you can use the token to sign into Kubernetes Dashboard. But this account do not have any permissions to all the content on dashboard, we need to create an admin account. But there is no deployments, no pods… (Because of the permission of serviceaccount:kubernetes-dashboard: “system:serviceaccount:kubernetes-dashboard:kubernetes-dashboard” cannot list resource “replicationcontrollers” in API group \"\" in the namespace “default”) I will add tutorial for adding cluster role and service account into kubernetes. ","date":"2021-10-02","objectID":"/hugo/2021/10/kubenetes-on-centos/:6:1","tags":["Cloud Native","Kubernetes"],"title":"Kubenetes on Centos","uri":"/hugo/2021/10/kubenetes-on-centos/"},{"categories":["Kubernetes"],"content":"Conclusion If you want to reload the certs afterward, run this command: kubeadm init phase upload-certs --upload-certs Join cluster with master node: kubeadm join k8s-master01:6443 --token 0yj7hj.u6i2pv98o522rt99 \\ --discovery-token-ca-cert-hash sha256:a4507c9a70a7c36543f4913b8a636c2b8a24a73ff4aefec6dd43144a40188437 \\ --control-plane --certificate-key 82441af4e2a70d7de93a15dbdde52a165e1cf6184d98c9ccd4b2d64bc01d55c8 Join cluster with worker node: kubeadm join k8s-master01:6443 --token 0yj7hj.u6i2pv98o522rt99 \\ --discovery-token-ca-cert-hash sha256:a4507c9a70a7c36543f4913b8a636c2b8a24a73ff4aefec6dd43144a40188437 How to access kubernetes dashboard remotely: (Kubernetes Dashboard is in your virtual machine, but you want to access it on local machine) # command ssh -L \u003cport whatever you like\u003e:127.0.0.1:8001 -N -f -l \u003cusername of kubernetes server\u003e \u003ckubernetes server ip\u003e -P 22 # Example ssh -L 8001:127.0.0.1:8001 -N -f -l leiyongqi 192.168.2.60 -P 22 Tips If you specify an address for proxy, if you want to access on local machine rather than virtual machine, you need to change the command above: ssh -L \u003cport whatever you like\u003e:\u003cthe address you specified in kubectl proxy command\u003e:8001 -N -f -l \u003cusername of kubernetes server\u003e \u003ckubernetes server ip\u003e -P 22 ","date":"2021-10-02","objectID":"/hugo/2021/10/kubenetes-on-centos/:7:0","tags":["Cloud Native","Kubernetes"],"title":"Kubenetes on Centos","uri":"/hugo/2021/10/kubenetes-on-centos/"},{"categories":["Kubernetes"],"content":"Reference Creating a cluster with kubeadm Creating Highly Available clusters with kubeadm Install Docker Engine on CentOS How can I remotely access kubernetes dashboard with token no endpoints available for service \"kubernetes-dashboard\" ","date":"2021-10-02","objectID":"/hugo/2021/10/kubenetes-on-centos/:8:0","tags":["Cloud Native","Kubernetes"],"title":"Kubenetes on Centos","uri":"/hugo/2021/10/kubenetes-on-centos/"},{"categories":["Programming"],"content":"Hello Golang Golang is developed and published by Google, Kubernetes - which is know as a tool for container orchestration, is mainly developed by Go, so Go is very important in Cloud Native. In this article, we are gonna introduce all kinds of grammars and data structure in Golang, also we will share some tips for programming. ","date":"2021-10-02","objectID":"/hugo/2021/10/golang-fundamentals/:1:0","tags":["Golang"],"title":"Golang Fundamentals","uri":"/hugo/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"Declaring and Assignment Declaring a variable in Go is similar to JavaScript, you can see following example: // var 是声明变量的关键字，如果只声明变量而不给它赋值 // 则该变量会被赋值为该类型的零值（zero value） var num int // := is operator of declaring and assignment // the workflow is: // 1. Declaring a variable named num // 2. Assign 10 to variable num num := 10 But you need to pay attention to that zero value of each type is different, such as zero value of int is 0, floating point value’s zero value is 0.0, string is \"\" (empty string). Variables like struct or pointer type, their zero value is nil. ","date":"2021-10-02","objectID":"/hugo/2021/10/golang-fundamentals/:2:0","tags":["Golang"],"title":"Golang Fundamentals","uri":"/hugo/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"Primitive Type in Go ","date":"2021-10-02","objectID":"/hugo/2021/10/golang-fundamentals/:3:0","tags":["Golang"],"title":"Golang Fundamentals","uri":"/hugo/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"Integers Signed Integers: Type Size Range int8 8 bits -128 to 127 int16 16 bits -215 to 215 -1 int32 32 bits -231 to 231 -1 int64 64 bits -263 to 263 -1 int Platform dependent Platform dependent The size of the generic int type is platform dependent. It is 32 bits wide on a 32-bit system and 64-bits wide on a 64-bit system. Unsigned Integers: Type Size Range uint8 8 bits 0 to 255 uint16 16 bits 0 to 216 -1 uint32 32 bits 0 to 232 -1 uint64 64 bits 0 to 264 -1 uint Platform dependent Platform dependent The size of uint type is platform dependent. It is 32 bits wide on a 32-bit system and 64-bits wide on a 64-bit system. Tips: When you are working with integer values, you should always use the int data type unless you have a good reason to use the sized or unsigned integer types. There are two additional type that are alias for uint8 and int32 data types: Type Alias For byte uint8 rune int32 In Go, rune and byte data types are used to distinguish characters and integers. Golang doesn’t have char type, it uses byte and rune to represent character value. But they are essentially integers. var firstLetter = 'a' var lastLetter byte = 'z' byte can be converted to ASCII code, for example firstLetter can represents 97. rune value can be converted to code in Unicode as following shows: package main import \"fmt\" func main() { var myByte byte = 'a' var myRune rune = '♥' fmt.Printf(\"%c = %d and %c = %U\\n\", myByte, myByte, myRune, myRune) } # Output a = 97 and ♥ = U+2665 Variable a is converted to 97 and rune variable with a unicode value ‘♥’ is converted to corresponding unicode codepoint U+2665, where U+ means unicode and the numbers are hexadecimal, which is essentially an integer. ","date":"2021-10-02","objectID":"/hugo/2021/10/golang-fundamentals/:3:1","tags":["Golang"],"title":"Golang Fundamentals","uri":"/hugo/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"Float Go has two floating point type: float32: Occupy 32 bits in memory and store values in single precision floating point format. float64: Occupy 64 bits in memory and store values in double precision floating point format. ","date":"2021-10-02","objectID":"/hugo/2021/10/golang-fundamentals/:3:2","tags":["Golang"],"title":"Golang Fundamentals","uri":"/hugo/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"Collections ","date":"2021-10-02","objectID":"/hugo/2021/10/golang-fundamentals/:4:0","tags":["Golang"],"title":"Golang Fundamentals","uri":"/hugo/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"Arrays In Go, array is a fixed-length data type which contains contiguous memory block of elements of same type. Let’s see how to declare an array: // Declare an integer array with length 5. Each element in it will be assigned 0 by default. // Because 0 is zero value of int var arr [5]int // Decalre an integer array with 5 elements and initialized. arr := [5]int{1,2,3,4,5} // Go will identify its length based on the initialized elements. arr := [...]int{1,2,3} // Declare an integer array and initialize specific elements. arr := [5]int{1: 20, 3: 40} Attention： Once array is declared, we can’t change its length and type。 It’s expensive to pass array between functions，if you really need to pass array to a function, consider pass its pointer。 Declare an array with one million elements will allocate 8 megabytes memory on 64-bit system。 When pass array between functions, every call to the function, 8 megabytes has to be allocated on the stack, then all of the 8 megabytes array will be copied into that allocation。 But you can pass a pointer to the array and only need to copy eight bytes instead of eight megabytes on the stack。 ","date":"2021-10-02","objectID":"/hugo/2021/10/golang-fundamentals/:4:1","tags":["Golang"],"title":"Golang Fundamentals","uri":"/hugo/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"Slices ","date":"2021-10-02","objectID":"/hugo/2021/10/golang-fundamentals/:4:2","tags":["Golang"],"title":"Golang Fundamentals","uri":"/hugo/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"Maps ","date":"2021-10-02","objectID":"/hugo/2021/10/golang-fundamentals/:4:3","tags":["Golang"],"title":"Golang Fundamentals","uri":"/hugo/2021/10/golang-fundamentals/"}]