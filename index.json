[{"categories":["Machine Learning"],"content":"This article is for the solution of week 2 assignment of Machine Learning by Andrew Ng. ","date":"2021-10-30","objectID":"/2021/10/machine-learning-week2/:0:0","tags":["Linear Regression","Machine Learning"],"title":"Machine Learning Week2 Assignment","uri":"/2021/10/machine-learning-week2/"},{"categories":["Machine Learning"],"content":"Assignment Introduction In this exercise, you need to implement one variable linear regression. The course has provided several files you would like to use and some of them you need to modify to implement the algorithm. Following list is the files they provide: ex1.m - Octave/MATLAB script that steps you through the exercise ex1 multi.m - Octave/MATLAB script for the later parts of the exercise ex1data1.txt - Dataset for linear regression with one variable ex1data2.txt - Dataset for linear regression with multiple variables submit.m - Submission script that sends your solutions to our servers (*) warmUpExercise.m - Simple example function in Octave/MATLAB (*) plotData.m - Function to display the dataset (*) computeCost.m - Function to compute the cost of linear regression (*) gradientDescent.m - Function to run gradient descent (†) computeCostMulti.m - Cost function for multiple variables (†) gradientDescentMulti.m - Gradient descent for multiple variables (†) featureNormalize.m - Function to normalize features (†) normalEqn.m - Function to compute the normal equations * indicates files you will need to complete † indicates optional exercises ","date":"2021-10-30","objectID":"/2021/10/machine-learning-week2/:1:0","tags":["Linear Regression","Machine Learning"],"title":"Machine Learning Week2 Assignment","uri":"/2021/10/machine-learning-week2/"},{"categories":["Machine Learning"],"content":"Linear Regression with One Variable ","date":"2021-10-30","objectID":"/2021/10/machine-learning-week2/:2:0","tags":["Linear Regression","Machine Learning"],"title":"Machine Learning Week2 Assignment","uri":"/2021/10/machine-learning-week2/"},{"categories":["Machine Learning"],"content":"Warm Up Exercise In warmUpExercise.m file, you need to write a program to output an 5x5 identity matrix. functionA =warmUpExercise()%WARMUPEXERCISE Example function in octave % A = WARMUPEXERCISE() is an example function that returns the 5x5 identity matrix A = []; % ============= YOUR CODE HERE ============== % Instructions: Return the 5x5 identity matrix % In octave, we return values by defining which variables % represent the return values (at the top of the file) % and then set them accordingly. A = eye(5); % =========================================== end ","date":"2021-10-30","objectID":"/2021/10/machine-learning-week2/:2:1","tags":["Linear Regression","Machine Learning"],"title":"Machine Learning Week2 Assignment","uri":"/2021/10/machine-learning-week2/"},{"categories":["Machine Learning"],"content":"Plot Data In plotData.m file, you need to plot the data using X and y passed as parameters. functionplotData(x, y)%PLOTDATA Plots the data points x and y into a new figure % PLOTDATA(x,y) plots the data points and gives the figure axes labels of % population and profit. figure; % open a new figure window % ====================== YOUR CODE HERE ====================== % Instructions: Plot the training data into a figure using the % \"figure\" and \"plot\" commands. Set the axes labels using % the \"xlabel\" and \"ylabel\" commands. Assume the % population and revenue data have been passed in % as the x and y arguments of this function. % % Hint: You can use the 'rx' option with plot to have the markers % appear as red crosses. Furthermore, you can make the % markers larger by using plot(..., 'rx', 'MarkerSize', 10); plot(x,y,'rx','MarkerSize',8) % ============================================================ end ","date":"2021-10-30","objectID":"/2021/10/machine-learning-week2/:2:2","tags":["Linear Regression","Machine Learning"],"title":"Machine Learning Week2 Assignment","uri":"/2021/10/machine-learning-week2/"},{"categories":["Machine Learning"],"content":"Compute Cost Function Cost function is one of the important parts in week 2. Following is the formula of cost function: $$ J(\\theta_0, \\theta_1,…,\\theta_n) = \\frac{1}{2m}\\sum_{i=1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)})^2 $$ Because we had $h_{\\theta}(x) = \\theta_0 + \\theta_1x$, it equals to $h_{\\theta}(x) = \\theta_0x_0 + \\theta_1x_1$ where $x_0 = 1$. So we can simplify the linear model: Then we can define uppercase X as “designed matrix”, which contains all training examples: So above cost function can be simplified as follows: $$ J(\\theta) = \\frac{1}{2m}(\\theta^{T}X - y)^2 $$ Finally we have the correct code: functionJ =computeCost(X, y, theta)%COMPUTECOST Compute cost for linear regression % J = COMPUTECOST(X, y, theta) computes the cost of using theta as the % parameter for linear regression to fit the data points in X and y % Initialize some useful values m = length(y); % number of training examples % You need to return the following variables correctly J = 0; % ====================== YOUR CODE HERE ====================== % Instructions: Compute the cost of a particular choice of theta % You should set J to the cost. J = (1 / (2 * m)) * sum((X * theta - y) .^ 2); % ========================================================================= end ","date":"2021-10-30","objectID":"/2021/10/machine-learning-week2/:2:3","tags":["Linear Regression","Machine Learning"],"title":"Machine Learning Week2 Assignment","uri":"/2021/10/machine-learning-week2/"},{"categories":["Machine Learning"],"content":"Gradient Descent Andrew Ng has clarified very clearly in the video lectures, so let’s see the final answer: function[theta, J_history] =gradientDescent(X, y, theta, alpha, num_iters)%GRADIENTDESCENT Performs gradient descent to learn theta % theta = GRADIENTDESCENT(X, y, theta, alpha, num_iters) updates theta by % taking num_iters gradient steps with learning rate alpha % Initialize some useful values m = length(y); % number of training examples J_history = zeros(num_iters, 1); for iter = 1:num_iters % ====================== YOUR CODE HERE ====================== % Instructions: Perform a single gradient step on the parameter vector % theta. % % Hint: While debugging, it can be useful to print out the values % of the cost function (computeCost) and gradient here. % temp = zeros(length(theta), 1); for it = 1:length(temp) temp(it) = theta(it) - (alpha / m) * sum((X * theta - y) .* X(:,it)); end theta = temp; % ============================================================ % Save the cost J in every iteration J_history(iter) = computeCost(X, y, theta); end end As Andrew mentioned in video lecture we need to simultaneously update $\\theta_j$, so we created one temp vector to save $\\theta_0$ and $\\theta_1$. ","date":"2021-10-30","objectID":"/2021/10/machine-learning-week2/:2:4","tags":["Linear Regression","Machine Learning"],"title":"Machine Learning Week2 Assignment","uri":"/2021/10/machine-learning-week2/"},{"categories":["Machine Learning"],"content":"Linear Regression with Multiple Variables (Optional) Because cost function and gradient descent algorithm above are compatible for multiple variables, we just need to copy the implementations to respective files. ","date":"2021-10-30","objectID":"/2021/10/machine-learning-week2/:3:0","tags":["Linear Regression","Machine Learning"],"title":"Machine Learning Week2 Assignment","uri":"/2021/10/machine-learning-week2/"},{"categories":["Machine Learning"],"content":"Normal Equation When Professor Andrew was teaching about Normal Equation, I was not understand well about the derivation of cost function. But now I worked it out. Recall the cost function: $J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^{m}(h_\\theta(x) - y)^2$. We can vectorized it to: $J(\\theta) = \\frac{1}{2m}(X\\theta - y)^T(X\\theta - y)$. To solve each $\\theta$, we set partial derivative with respect to each $\\theta$ equals to 0: $\\frac{\\partial}{\\partial_{\\theta}}J(\\theta) = 0$. To derive the equation, we get: $\\theta = (X^TX)^{-1}X^Ty$. So far, we got the equation that how to compute $\\theta$. Let’s see how to code: function[theta] =normalEqn(X, y)%NORMALEQN Computes the closed-form solution to linear regression % NORMALEQN(X,y) computes the closed-form solution to linear % regression using the normal equations. theta = zeros(size(X, 2), 1); % ====================== YOUR CODE HERE ====================== % Instructions: Complete the code to compute the closed form solution % to linear regression and put the result in theta. % % ---------------------- Sample Solution ---------------------- theta = pinv(X' * X) * X' * y; % ------------------------------------------------------------- % ============================================================ end ","date":"2021-10-30","objectID":"/2021/10/machine-learning-week2/:4:0","tags":["Linear Regression","Machine Learning"],"title":"Machine Learning Week2 Assignment","uri":"/2021/10/machine-learning-week2/"},{"categories":["Machine Learning"],"content":"Final After finished all the files, I submitted my assignment. Congratulations, you have done the assignment of Week 2! ","date":"2021-10-30","objectID":"/2021/10/machine-learning-week2/:5:0","tags":["Linear Regression","Machine Learning"],"title":"Machine Learning Week2 Assignment","uri":"/2021/10/machine-learning-week2/"},{"categories":null,"content":" I am a software engineer in Rakuten, serving for Rakuten Ichiba. ","date":"2021-10-03","objectID":"/about/:0:0","tags":null,"title":"About me","uri":"/about/"},{"categories":null,"content":"Skills Programing Language: Java 8, 11; Golang Framework: Spring Framework, Spring Boot 2.x, Spring Cloud, Reactor(Spring WebFlux) Ops: Kubernetes, Docker ","date":"2021-10-03","objectID":"/about/:1:0","tags":null,"title":"About me","uri":"/about/"},{"categories":null,"content":"Experience Rakuten Group, Inc. 2021-04-01 ~ now Applications Engineer - ECMPD …TODO Rakuten Group, Inc. 2021-04-01 ~ now Software Engineer …TODO ","date":"2021-10-03","objectID":"/about/:2:0","tags":null,"title":"About me","uri":"/about/"},{"categories":["AWS"],"content":"IAM - Identity Access Management IAM consists of the followings: Users Groups Roles Policies We can use follow json data to custom policies: { \"Version\": \"2020-03-14\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"*\", \"Resource\": \"*\" } ] } ","date":"2021-10-03","objectID":"/2021/10/aws-s3-and-iam-summary/:0:0","tags":["S3","IAM"],"title":"Aws S3 and Iam Summary","uri":"/2021/10/aws-s3-and-iam-summary/"},{"categories":["AWS"],"content":"IAM Knowledge Point IAM is universal. Does not apply to regions at this time The “root account” is simply the account created when first setip your AWS account. It has complete Admin access. New Users have No Permissions when first created New Users are assigned Access Key ID and Access Keys when first created Access Key ID and Access Keys are not same as passwords. We can not use them to login in to the AWS console. But we can use them to access AWS via then APIs nad Command Line. We can only view Access Keys once. If we lose them, we have to regenerate them. IAM requires us to setup Mutifactor Authentication on our root account We can create and customise our own password rotation policies S3- Simple Storage Service ","date":"2021-10-03","objectID":"/2021/10/aws-s3-and-iam-summary/:1:0","tags":["S3","IAM"],"title":"Aws S3 and Iam Summary","uri":"/2021/10/aws-s3-and-iam-summary/"},{"categories":["AWS"],"content":"S3 Knowledge Point S3 is Object-based, allows us to upload files. Files can be from 0 Bytes to 5 TB. unlimited storage. Files are stored is Buckets. S3 is a universal namespace. So the name of buckets have to be unique globally. This is what the S3 url looks like: https://mscloudplatform.s3.amazonaws.com Not suitable to install an operation system on like EBS. Successful uploads will generate a HTTP 200 status code. By default, all newly created buckets are PRIVATE. We can setup access control to our buckets using: Bucket Policies Access Control Lists S3 Buckets can be configured to create access logs which log all requests made to the S3 buckets. This can be sent to another bucket and even another bucket in another account. ","date":"2021-10-03","objectID":"/2021/10/aws-s3-and-iam-summary/:2:0","tags":["S3","IAM"],"title":"Aws S3 and Iam Summary","uri":"/2021/10/aws-s3-and-iam-summary/"},{"categories":["AWS"],"content":"The Key Fundamentals of S3 Key (This is simply te name of the object) Value (This is simply the data and is made up of a sequence of bytes) Version ID (Important for versioning) Metadata (Data about data you are storing) Subresources: Access Control Lists Torrents Read after Write consistency for PUTS of new Objects Eventual Consistency for overwrite PUTS and DELETES (can take some time to propagate) S3 Storage Level There are some different level of S3 storage we can choose when we upload Objects to S3 Buckets. ","date":"2021-10-03","objectID":"/2021/10/aws-s3-and-iam-summary/:3:0","tags":["S3","IAM"],"title":"Aws S3 and Iam Summary","uri":"/2021/10/aws-s3-and-iam-summary/"},{"categories":["AWS"],"content":"Understand how to get the best value out of S3 Storage Cost (High to Low): S3 Standard S3 - IA (Infrequently Accessed) S3 - Intelligent Tiering S3 One Zone - IA (not recommend) S3 Glacier S3 Glacier Deep Archive ","date":"2021-10-03","objectID":"/2021/10/aws-s3-and-iam-summary/:4:0","tags":["S3","IAM"],"title":"Aws S3 and Iam Summary","uri":"/2021/10/aws-s3-and-iam-summary/"},{"categories":["AWS"],"content":"S3 Encryption Encryption in Transit is achieved by: SSL/TLS Encryption at Rest (Server Side) is achieved by S3 managed Keys - SSE-S3 AWS Key Management Service, Managed Keys - SSE-KMS Server Side Encrytion With Customer: Provided Keys - SSE-C Client Side Encryption ","date":"2021-10-03","objectID":"/2021/10/aws-s3-and-iam-summary/:5:0","tags":["S3","IAM"],"title":"Aws S3 and Iam Summary","uri":"/2021/10/aws-s3-and-iam-summary/"},{"categories":["AWS"],"content":"Best Practices with AWS Organizations(Enterprise only) Best Practices with AWS Organizations ","date":"2021-10-03","objectID":"/2021/10/aws-s3-and-iam-summary/:6:0","tags":["S3","IAM"],"title":"Aws S3 and Iam Summary","uri":"/2021/10/aws-s3-and-iam-summary/"},{"categories":["AWS"],"content":"Share S3 buckets across accounts Using Bucket Policies \u0026 IAM (applies across the entire bucket). Programmatic Access Only (APIs 访问). Using Bucket ACLs \u0026 IAM (individual objects). Programmatic Access Only. Cross-account IAM Roles. Programmatic and Console access. ","date":"2021-10-03","objectID":"/2021/10/aws-s3-and-iam-summary/:7:0","tags":["S3","IAM"],"title":"Aws S3 and Iam Summary","uri":"/2021/10/aws-s3-and-iam-summary/"},{"categories":["AWS"],"content":"Cross Region Replication Versioning must be enbaled on both the source and destination buckets.(版本控制必须要在source和target同时启用) Regions must be unique. Files in an existing bucket are not replicated automatically. (已经存在于桶的文件不会自动replicate) All subsequent updated files will be replicated automatically. (所有之后的文件上传或者更新都会自动replicate) Delete markets are not replicated. (删除标记不会replicate) Deleting individual versions or delete markers will not be replicated. (删除单独的版本或删除delete markers不会被replicate) Understand what Cross Region Replication is at a high level. ","date":"2021-10-03","objectID":"/2021/10/aws-s3-and-iam-summary/:8:0","tags":["S3","IAM"],"title":"Aws S3 and Iam Summary","uri":"/2021/10/aws-s3-and-iam-summary/"},{"categories":["AWS"],"content":"Lifecycle Policies Automates moving your objects between the different storage tiers. (可以将你的objects自动在不同的存储级别之间移动) Can be used in conjuction with versioning. (可以和版本控制结合使用) Can be applied to current versions and previous versions.(可以应用于当前版本和旧版本) CloudFront ","date":"2021-10-03","objectID":"/2021/10/aws-s3-and-iam-summary/:9:0","tags":["S3","IAM"],"title":"Aws S3 and Iam Summary","uri":"/2021/10/aws-s3-and-iam-summary/"},{"categories":["AWS"],"content":"CloudFront Knowledge Point Edge Location - This is the location where content will be cached. This is separate to an AWS Region/AZ (content被缓存的地方，独立于AWS地区和可用区) Origin - This is the origin of all the files that the CDN will distribute. This can be either an S3 Bucket, an EC2 Instance, an Elastic Load Balancer, or Route53. (这是CDN分发的所有文件资源的来源。可以是S3 Bucket，可以是一个EC2实例，也可以是ELB，或者Route53) Distribution - This is the name given the CDN which consists of a collection of Edge Locations. (这是给定的由Edge Locations集合组成的CDN的名称) Web Distribution - Typically used for Websites. (通常用于网站) RTMP - Used for Media Streaming. Edge locations are not just READ only - you can write to them too. (Edge locations 不止是只读，我们也可以将数据写入edge location) Objects are cached for the life of the TTL(Time To Live). (对象只在TTL的生命周期中被缓存) You can clear cached objects, but you will be charged. (我们可一清楚缓存的对象，但是需要收费) Storage Gateway There are some kinds of gateways: File Gateway For flat files, stored directly on S3 Volume Gateway Stored Volumes - Entire Dataset is stored on site and is aynchronously backed up to S3. (存储卷 - 整个数据集都存储在站点上并异步备份至S3) Cached Volumes - Entire Dataset is Stored on S3 and the most frequently accessed data is cached on site. (缓存卷 - 整个数据集都存储在S3中，最常访问的数据被缓存在站点上) Gateway Virtual Tape Library USed for backup and uses popular backup applications like NetBackup, Backup Exec, Veeam etc. ","date":"2021-10-03","objectID":"/2021/10/aws-s3-and-iam-summary/:10:0","tags":["S3","IAM"],"title":"Aws S3 and Iam Summary","uri":"/2021/10/aws-s3-and-iam-summary/"},{"categories":["AWS"],"content":"Athena ","date":"2021-10-03","objectID":"/2021/10/athena-and-macie/:1:0","tags":["Athena","Macie"],"title":"Athena and Macie","uri":"/2021/10/athena-and-macie/"},{"categories":["AWS"],"content":"What is Athena Athena is a interactive query service which enables you to analyse and query data located in S3 using standard SQL. Serverless, nothing to provision, pay per query / per TB scanned No need to set up complex Extract/Transform/Load(ETL) process Works directly with data stored in S3 ","date":"2021-10-03","objectID":"/2021/10/athena-and-macie/:1:1","tags":["Athena","Macie"],"title":"Athena and Macie","uri":"/2021/10/athena-and-macie/"},{"categories":["AWS"],"content":"Athena Use Case What can Athena be used for? Query log files stored in S3: e.g. ELB logs, S3 access logs etc Generate business reports on data stored in S3 Analyse AWS cost nad usage reports Run queries on click-stream data ","date":"2021-10-03","objectID":"/2021/10/athena-and-macie/:1:2","tags":["Athena","Macie"],"title":"Athena and Macie","uri":"/2021/10/athena-and-macie/"},{"categories":["AWS"],"content":"Macie ","date":"2021-10-03","objectID":"/2021/10/athena-and-macie/:2:0","tags":["Athena","Macie"],"title":"Athena and Macie","uri":"/2021/10/athena-and-macie/"},{"categories":["AWS"],"content":"What is PII(Personally Identifiable Information)? Personal data used to establish an indevidual’s identity Could be exploited by criminals, used in identity theft and financial fraud Home address, emal address Passport number, driver’s license number … ","date":"2021-10-03","objectID":"/2021/10/athena-and-macie/:2:1","tags":["Athena","Macie"],"title":"Athena and Macie","uri":"/2021/10/athena-and-macie/"},{"categories":["AWS"],"content":"What is Macie Security service which uses Machine Learning and NLP to discover, classify and protect sensitive data stored in S3 Uses AI to recognise if your S3 objects contain sensitive data such as PII Dashboards, reporting and alerts Works directly with data stored in S3 Can also analyze CloudTrail logs Great for PCI-DSS and preventing ID theft ","date":"2021-10-03","objectID":"/2021/10/athena-and-macie/:2:2","tags":["Athena","Macie"],"title":"Athena and Macie","uri":"/2021/10/athena-and-macie/"},{"categories":["AWS"],"content":"Macie Exam Tips Remember What is Macie used for: Uses AI to analyze data in S3 and helps identify PII Analyse CloudTrail logs for suspicious API activity Dashboards, Reports and Alerting PCI-DSS compliance and preventing ID theft ","date":"2021-10-03","objectID":"/2021/10/athena-and-macie/:2:3","tags":["Athena","Macie"],"title":"Athena and Macie","uri":"/2021/10/athena-and-macie/"},{"categories":["Cloud Native"],"content":"Prerequisite A compatible Linux host. The Kubernetes project provides generic instructions for Linux distributions based on Debian and Red Hat, and those distributions without a package manager. 2 GB or more of RAM per machine (any less will leave little room for your apps). 2 CPUs or more. Full network connectivity between all machines in the cluster (public or private network is fine). Unique hostname, MAC address, and product_uuid for every node. See here for more details. Certain ports are open on your machines. See here for more details. Swap disabled. You MUST disable swap in order for the kubelet to work properly. ","date":"2021-10-02","objectID":"/2021/10/kubenetes-on-centos/:1:0","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"Letting iptables see bridged traffic Make sure that the br_netfilter module is loaded. This can be done by running lsmod | grep br_netfilter. To load it explicitly call sudo modprobe br_netfilter. lsmod | grep br_netfilter # br_netfilter 22256 0 # bridge 151336 2 br_netfilter,ebtable_broute sudo modprobe br_netfilter As a requirement for your Linux Node’s iptables to correctly see bridged traffic, you should ensure net.bridge.bridge-nf-call-iptables is set to 1 in your sysctl config. sudo tee /etc/sysctl.d/kubernetes.conf\u003c\u003cEOF net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 EOF sudo sysctl --system ","date":"2021-10-02","objectID":"/2021/10/kubenetes-on-centos/:1:1","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"Check Required Ports ","date":"2021-10-02","objectID":"/2021/10/kubenetes-on-centos/:1:2","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"Install Docker Refer: Install Docker Engine on CentOS ","date":"2021-10-02","objectID":"/2021/10/kubenetes-on-centos/:1:3","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"Install Kubernetes ","date":"2021-10-02","objectID":"/2021/10/kubenetes-on-centos/:2:0","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"Prepare Kubernetes Servers Server Type Host Name Specs Master 192.168.2.60 2 CPUs, 2GB Ram Worker 192.168.2.61 2 CPUs, 2GB Ram Worker 192.168.2.62 2 CPUs, 2GB Ram Here I used a VM which has 2 CPUs and 4GB Ram for master node. ","date":"2021-10-02","objectID":"/2021/10/kubenetes-on-centos/:2:1","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"Install kubeadm and kubectl cat \u003c\u003cEOF | sudo tee /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\\$basearch enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg exclude=kubelet kubeadm kubectl EOF sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes sudo systemctl enable --now kubelet ","date":"2021-10-02","objectID":"/2021/10/kubenetes-on-centos/:2:2","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"Disable SELinux and Swap # Set SELinux in permissive mode (effectively disabling it) sudo setenforce 0 sudo sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config # Disable swap sudo sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab sudo swapoff -a ","date":"2021-10-02","objectID":"/2021/10/kubenetes-on-centos/:2:3","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"Configure Firewall Enable Master Node Ports: sudo firewall-cmd --add-port={6443,2379-2380,10250,10251,10252,5473,179,5473}/tcp --permanent sudo firewall-cmd --add-port={4789,8285,8472}/udp --permanent sudo firewall-cmd --reload Enable Worker Node Ports: sudo firewall-cmd --add-port={10250,30000-32767,5473,179,5473}/tcp --permanent sudo firewall-cmd --add-port={4789,8285,8472}/udp --permanent sudo firewall-cmd --reload ","date":"2021-10-02","objectID":"/2021/10/kubenetes-on-centos/:3:0","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"Verify the installation In order to verify whether the installation is successful, we are gonna create a cluster using kubeadm. ","date":"2021-10-02","objectID":"/2021/10/kubenetes-on-centos/:4:0","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"Initialize Kubernetes Control Plane First of all, I added a host name to /etc/hosts , as below: 192.168.2.60 k8s-master01 k8s-master01.torres.com Then I run below commands to initialize the control plane on master node: # (Optional) You can run this commands to verify the connection with gcr.io sudo kubeadm config images pull # Init Control plane sudo kubeadm init --control-plane-endpoint=k8s-master01.torres.com --node-name=k8s-master01 --upload-certs Then you can see logs as follows: [init] Using Kubernetes version: v1.21.1 [preflight] Running pre-flight checks [WARNING Firewalld]: firewalld is active, please ensure ports [6443 10250] are open or your cluster may not function correctly [WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\". Please follow the guide at https://kubernetes.io/docs/setup/cri/ [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using 'kubeadm config images pull' [certs] Using certificateDir folder \"/etc/kubernetes/pki\" [certs] Generating \"ca\" certificate and key [certs] Generating \"apiserver\" certificate and key [certs] apiserver serving cert is signed for DNS names [k8s-master01 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local localhost.localdomain] and IPs [10.96.0.1 192.168.2.60] [certs] Generating \"apiserver-kubelet-client\" certificate and key [certs] Generating \"front-proxy-ca\" certificate and key [certs] Generating \"front-proxy-client\" certificate and key [certs] Generating \"etcd/ca\" certificate and key [certs] Generating \"etcd/server\" certificate and key [certs] etcd/server serving cert is signed for DNS names [localhost localhost.localdomain] and IPs [192.168.2.60 127.0.0.1 ::1] [certs] Generating \"etcd/peer\" certificate and key [certs] etcd/peer serving cert is signed for DNS names [localhost localhost.localdomain] and IPs [192.168.2.60 127.0.0.1 ::1] [certs] Generating \"etcd/healthcheck-client\" certificate and key [certs] Generating \"apiserver-etcd-client\" certificate and key [certs] Generating \"sa\" key and public key [kubeconfig] Using kubeconfig folder \"/etc/kubernetes\" [kubeconfig] Writing \"admin.conf\" kubeconfig file [kubeconfig] Writing \"kubelet.conf\" kubeconfig file [kubeconfig] Writing \"controller-manager.conf\" kubeconfig file [kubeconfig] Writing \"scheduler.conf\" kubeconfig file [kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\" [kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\" [kubelet-start] Starting the kubelet [control-plane] Using manifest folder \"/etc/kubernetes/manifests\" [control-plane] Creating static Pod manifest for \"kube-apiserver\" [control-plane] Creating static Pod manifest for \"kube-controller-manager\" [control-plane] Creating static Pod manifest for \"kube-scheduler\" [etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\" [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s [apiclient] All control plane components are healthy after 13.004835 seconds [upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace [kubelet] Creating a ConfigMap \"kubelet-config-1.21\" in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Storing the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace [upload-certs] Using certificate key: b8cb86fb2bd01029d07cd1c67a6ae9ca358655595cef1cc7bec5253b64a81037 [mark-control-plane] Marking the node localhost.localdomain as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io","date":"2021-10-02","objectID":"/2021/10/kubenetes-on-centos/:4:1","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"Verification We can run this command to verify the cluster we just created: kubectl cluster-info Kubernetes control plane is running at https://k8s-master01:6443 CoreDNS is running at https://k8s-master01:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. Also if you want to see the nodes: kubectl get nodes NAME STATUS ROLES AGE VERSION localhost.localdomain NotReady control-plane,master 3m15s v1.21.1 If you see the status of the nodes you created is not ready, you can check if all the pods in the node is RUNNING: kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-558bd4d5db-9szx5 0/1 Pending 0 7m31s kube-system coredns-558bd4d5db-lx7jv 0/1 Pending 0 7m31s kube-system etcd-localhost.localdomain 1/1 Running 0 7m36s kube-system kube-apiserver-localhost.localdomain 1/1 Running 0 7m36s kube-system kube-controller-manager-localhost.localdomain 1/1 Running 0 7m36s kube-system kube-proxy-2skgn 1/1 Running 0 7m31s kube-system kube-scheduler-localhost.localdomain 1/1 Running 0 7m38s The coredns is still Pending, so we have to install a network plugin to make the coredns work. ","date":"2021-10-02","objectID":"/2021/10/kubenetes-on-centos/:4:2","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"Install network plugin - Calico kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml onfigmap/calico-config created customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/kubecontrollersconfigurations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created clusterrole.rbac.authorization.k8s.io/calico-node created clusterrolebinding.rbac.authorization.k8s.io/calico-node created daemonset.apps/calico-node created serviceaccount/calico-node created deployment.apps/calico-kube-controllers created serviceaccount/calico-kube-controllers created Warning: policy/v1beta1 PodDisruptionBudget is deprecated in v1.21+, unavailable in v1.25+; use policy/v1 PodDisruptionBudget poddisruptionbudget.policy/calico-kube-controllers created Then run following command to see the service: kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system calico-kube-controllers-78d6f96c7b-9kd5b 1/1 Running 0 6m57s kube-system calico-node-f8fsw 1/1 Running 0 6m57s kube-system coredns-558bd4d5db-9szx5 1/1 Running 0 14m kube-system coredns-558bd4d5db-lx7jv 1/1 Running 0 14m kube-system etcd-localhost.localdomain 1/1 Running 0 14m kube-system kube-apiserver-localhost.localdomain 1/1 Running 0 14m kube-system kube-controller-manager-localhost.localdomain 1/1 Running 0 14m kube-system kube-proxy-2skgn 1/1 Running 0 14m kube-system kube-scheduler-localhost.localdomain 1/1 Running 0 14m After the installation of Network Plugin (Calico), we can see coredns is Running, and there are another two pods for calico network plugin. Now, we are going to install Kubernetes Dashboard! ","date":"2021-10-02","objectID":"/2021/10/kubenetes-on-centos/:5:0","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"Install Kubernetes Dashboard By default, the dashboar ui is not deployed, so we need to do it manually with following command: kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.2.0/aio/deploy/recommended.yaml # Then you can use this command to see the dashboard is running kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system calico-kube-controllers-78d6f96c7b-9kd5b 1/1 Running 0 9m41s kube-system calico-node-f8fsw 1/1 Running 0 9m41s kube-system coredns-558bd4d5db-9szx5 1/1 Running 0 17m kube-system coredns-558bd4d5db-lx7jv 1/1 Running 0 17m kube-system etcd-localhost.localdomain 1/1 Running 0 17m kube-system kube-apiserver-localhost.localdomain 1/1 Running 0 17m kube-system kube-controller-manager-localhost.localdomain 1/1 Running 0 17m kube-system kube-proxy-2skgn 1/1 Running 0 17m kube-system kube-scheduler-localhost.localdomain 1/1 Running 0 17m kubernetes-dashboard dashboard-metrics-scraper-856586f554-p7gxx 1/1 Running 0 44s kubernetes-dashboard kubernetes-dashboard-78c79f97b4-qs57f 1/1 Running 0 45s The yaml file above is a recommended config for production environment, it helps us to create service, service account, cluster role and deployment for kubernetes dashboard. You can access Dashboard using the kubectl command-line tool by running the following command: kubectl proxy This will start serving at localhost:8001 by default. Then you can access http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/ to see your dashboard. But there are some optional parameters for the command: kubectl proxy --address='192.168.2.60' --port=9001 --accept-hosts='^*$' --address: The IP address on which to serve on. -p --port: The port on which to run the proxy. Set to 0 to pick a random port. --accept-hosts: Regular expression for hosts that the proxy should accept. (使用正则表达式指定proxy应该接收的hosts) --api-prefix='/': Prefix to serve the proxied API under. For more details of the command, please use kubectl proxy --help. ","date":"2021-10-02","objectID":"/2021/10/kubenetes-on-centos/:6:0","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"Kubernetes Dashboard When every pod of kubenetes-dashboard is running, then you can access the dashboard. Now you can see the dashboar login screen, but it requires authentication at login. So you need to find the Token or Kubeconfig to sign in with following commands: # See secret in kubernetes-dashboard namespace kubectl -n kubernetes-dashboard get secret NAME TYPE DATA AGE default-token-p7rgf kubernetes.io/service-account-token 3 27m kubernetes-dashboard-certs Opaque 0 27m kubernetes-dashboard-csrf Opaque 1 27m kubernetes-dashboard-key-holder Opaque 2 27m kubernetes-dashboard-token-8kjgr kubernetes.io/service-account-token 3 27m # Get details of token kubectl -n kubernetes-dashboard describe secret kubernetes-dashboard-token-8kjgr Name: kubernetes-dashboard-token-8kjgr Namespace: kubernetes-dashboard Labels: \u003cnone\u003e Annotations: kubernetes.io/service-account.name: kubernetes-dashboard kubernetes.io/service-account.uid: d54e2160-e9b0-444d-93fc-5d38f8fa61ef Type: kubernetes.io/service-account-token Data ==== ca.crt: 1066 bytes namespace: 20 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6ImNKX2pGTG9fUXE0cmk1cE5oUkpPYzVoald2TXFWN2QySHBEV1RlclNlMWcifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZC10b2tlbi04a2pnciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImQ1NGUyMTYwLWU5YjAtNDQ0ZC05M2ZjLTVkMzhmOGZhNjFlZiIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlcm5ldGVzLWRhc2hib2FyZDprdWJlcm5ldGVzLWRhc2hib2FyZCJ9.YbuWfZ3Qu9hjQTEVpuR7FxGrjboO8OpjqY4tE1O86v9UD9OilCbb330QRCNbTPcobLfXvFHRsJ4MVY2LHaCM1s2y2fpGE3dGPpPs2XcLJj2Aw3e_mJKHy9sZHtjfAG0cFgWKhyr_LTEuxk3_0pEVMKtuk2WeSqoo37ADhUjR92G7dK0TGkahkNzOH0-I_Yn40oZn9wA9w0r4DCGd5q8s2c5piHd6jGOuRX-7_UKgVfc6GYkRngAsrVZTnqfZkjv0LoH8Egkmu2X3CRvMz4JrlyhScTPZ77Uck0PXVklU57tK1PdgPIcczlvVJtr4avyBZsS5Y9j5zjm7sSDvPMeuJQ Then you can use the token to sign into Kubernetes Dashboard. But this account do not have any permissions to all the content on dashboard, we need to create an admin account. But there is no deployments, no pods… (Because of the permission of serviceaccount:kubernetes-dashboard: “system:serviceaccount:kubernetes-dashboard:kubernetes-dashboard” cannot list resource “replicationcontrollers” in API group \"\" in the namespace “default”) I will add tutorial for adding cluster role and service account into kubernetes. ","date":"2021-10-02","objectID":"/2021/10/kubenetes-on-centos/:6:1","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"Conclusion If you want to reload the certs afterward, run this command: kubeadm init phase upload-certs --upload-certs Join cluster with master node: kubeadm join k8s-master01:6443 --token 0yj7hj.u6i2pv98o522rt99 \\ --discovery-token-ca-cert-hash sha256:a4507c9a70a7c36543f4913b8a636c2b8a24a73ff4aefec6dd43144a40188437 \\ --control-plane --certificate-key 82441af4e2a70d7de93a15dbdde52a165e1cf6184d98c9ccd4b2d64bc01d55c8 Join cluster with worker node: kubeadm join k8s-master01:6443 --token 0yj7hj.u6i2pv98o522rt99 \\ --discovery-token-ca-cert-hash sha256:a4507c9a70a7c36543f4913b8a636c2b8a24a73ff4aefec6dd43144a40188437 How to access kubernetes dashboard remotely: (Kubernetes Dashboard is in your virtual machine, but you want to access it on local machine) # command ssh -L \u003cport whatever you like\u003e:127.0.0.1:8001 -N -f -l \u003cusername of kubernetes server\u003e \u003ckubernetes server ip\u003e -P 22 # Example ssh -L 8001:127.0.0.1:8001 -N -f -l leiyongqi 192.168.2.60 -P 22 Tips If you specify an address for proxy, if you want to access on local machine rather than virtual machine, you need to change the command above: ssh -L \u003cport whatever you like\u003e:\u003cthe address you specified in kubectl proxy command\u003e:8001 -N -f -l \u003cusername of kubernetes server\u003e \u003ckubernetes server ip\u003e -P 22 ","date":"2021-10-02","objectID":"/2021/10/kubenetes-on-centos/:7:0","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/2021/10/kubenetes-on-centos/"},{"categories":["Cloud Native"],"content":"Reference Creating a cluster with kubeadm Creating Highly Available clusters with kubeadm Install Docker Engine on CentOS How can I remotely access kubernetes dashboard with token no endpoints available for service \"kubernetes-dashboard\" ","date":"2021-10-02","objectID":"/2021/10/kubenetes-on-centos/:8:0","tags":["Kubernetes"],"title":"Kubenetes on Centos","uri":"/2021/10/kubenetes-on-centos/"},{"categories":["Programming"],"content":"Hello Golang Golang is developed and published by Google, Kubernetes - which is know as a tool for container orchestration, is mainly developed by Go, so Go is very important in Cloud Native. In this article, we are gonna introduce all kinds of grammars and data structure in Golang, also we will share some tips for programming. ","date":"2021-10-02","objectID":"/2021/10/golang-fundamentals/:1:0","tags":["Golang"],"title":"Golang Fundamentals","uri":"/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"Declaring and Assignment Declaring a variable in Go is similar to JavaScript, you can see following example: // var 是声明变量的关键字，如果只声明变量而不给它赋值 // 则该变量会被赋值为该类型的零值（zero value） var num int // := is operator of declaring and assignment // the workflow is: // 1. Declaring a variable named num // 2. Assign 10 to variable num num := 10 But you need to pay attention to that zero value of each type is different, such as zero value of int is 0, floating point value’s zero value is 0.0, string is \"\" (empty string). Variables like struct or pointer type, their zero value is nil. ","date":"2021-10-02","objectID":"/2021/10/golang-fundamentals/:2:0","tags":["Golang"],"title":"Golang Fundamentals","uri":"/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"Primitive Type in Go ","date":"2021-10-02","objectID":"/2021/10/golang-fundamentals/:3:0","tags":["Golang"],"title":"Golang Fundamentals","uri":"/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"Integers Signed Integers: Type Size Range int8 8 bits -128 to 127 int16 16 bits -215 to 215 -1 int32 32 bits -231 to 231 -1 int64 64 bits -263 to 263 -1 int Platform dependent Platform dependent The size of the generic int type is platform dependent. It is 32 bits wide on a 32-bit system and 64-bits wide on a 64-bit system. Unsigned Integers: Type Size Range uint8 8 bits 0 to 255 uint16 16 bits 0 to 216 -1 uint32 32 bits 0 to 232 -1 uint64 64 bits 0 to 264 -1 uint Platform dependent Platform dependent The size of uint type is platform dependent. It is 32 bits wide on a 32-bit system and 64-bits wide on a 64-bit system. Tips: When you are working with integer values, you should always use the int data type unless you have a good reason to use the sized or unsigned integer types. There are two additional type that are alias for uint8 and int32 data types: Type Alias For byte uint8 rune int32 In Go, rune and byte data types are used to distinguish characters and integers. Golang doesn’t have char type, it uses byte and rune to represent character value. But they are essentially integers. var firstLetter = 'a' var lastLetter byte = 'z' byte can be converted to ASCII code, for example firstLetter can represents 97. rune value can be converted to code in Unicode as following shows: package main import \"fmt\" func main() { var myByte byte = 'a' var myRune rune = '♥' fmt.Printf(\"%c = %d and %c = %U\\n\", myByte, myByte, myRune, myRune) } # Output a = 97 and ♥ = U+2665 Variable a is converted to 97 and rune variable with a unicode value ‘♥’ is converted to corresponding unicode codepoint U+2665, where U+ means unicode and the numbers are hexadecimal, which is essentially an integer. ","date":"2021-10-02","objectID":"/2021/10/golang-fundamentals/:3:1","tags":["Golang"],"title":"Golang Fundamentals","uri":"/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"Float Go has two floating point type: float32: Occupy 32 bits in memory and store values in single precision floating point format. float64: Occupy 64 bits in memory and store values in double precision floating point format. ","date":"2021-10-02","objectID":"/2021/10/golang-fundamentals/:3:2","tags":["Golang"],"title":"Golang Fundamentals","uri":"/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"Collections ","date":"2021-10-02","objectID":"/2021/10/golang-fundamentals/:4:0","tags":["Golang"],"title":"Golang Fundamentals","uri":"/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"Arrays In Go, array is a fixed-length data type which contains contiguous memory block of elements of same type. Let’s see how to declare an array: // Declare an integer array with length 5. Each element in it will be assigned 0 by default. // Because 0 is zero value of int var arr [5]int // Decalre an integer array with 5 elements and initialized. arr := [5]int{1,2,3,4,5} // Go will identify its length based on the initialized elements. arr := [...]int{1,2,3} // Declare an integer array and initialize specific elements. arr := [5]int{1: 20, 3: 40} Attention： Once array is declared, we can’t change its length and type。 It’s expensive to pass array between functions，if you really need to pass array to a function, consider pass its pointer。 Declare an array with one million elements will allocate 8 megabytes memory on 64-bit system。 When pass array between functions, every call to the function, 8 megabytes has to be allocated on the stack, then all of the 8 megabytes array will be copied into that allocation。 But you can pass a pointer to the array and only need to copy eight bytes instead of eight megabytes on the stack。 ","date":"2021-10-02","objectID":"/2021/10/golang-fundamentals/:4:1","tags":["Golang"],"title":"Golang Fundamentals","uri":"/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"Slices ","date":"2021-10-02","objectID":"/2021/10/golang-fundamentals/:4:2","tags":["Golang"],"title":"Golang Fundamentals","uri":"/2021/10/golang-fundamentals/"},{"categories":["Programming"],"content":"Maps ","date":"2021-10-02","objectID":"/2021/10/golang-fundamentals/:4:3","tags":["Golang"],"title":"Golang Fundamentals","uri":"/2021/10/golang-fundamentals/"}]